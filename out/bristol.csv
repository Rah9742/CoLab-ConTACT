"Title","Href","Author","Date","Abstract","Keywords","University Name"
"AI in risk control","https://research-information.bris.ac.uk/en/publications/ai-in-risk-control","Comerford, JB.; Stone, JR.","1992","None","AI","University of Bristol"
"SMEs and Artificial Intelligence (AI): Antecedents and Consequences of AI-based B2B Practices","https://research-information.bris.ac.uk/en/publications/smes-and-artificial-intelligence-ai-antecedents-and-consequences-","Baabdullah, A.; Alalwan, A.; Slade, E.; Raman, R.; Khatatneh, K.","1 Oct 2021","Development of small and medium enterprises (SMEs) is a key approach to achieving economic growth in the Middle East and successful adoption of technology is vital for SMEs' success and continuity. Artificial intelligence (AI) is part of a new generation of technologies that can facilitate competitive advantage but currently there is a lack of evidence regarding AI applications in relation to B2B SMEs in Middle East countries. Therefore, this study empirically examines antecedents to, and consequences of, successful acceptance of AI practices by B2B SMEs in Saudi Arabia. A conceptual model based on the technology-organisation-environment framework is developed which considers the impact of AI enablers and AI readiness on the acceptance of AI practices, and the impact of this on relational governance, performance, and SMEs' AI-based business customer interaction. The conceptual model was tested using structural equation modelling of survey data collected from B2B SMEs (n = 392). The results showed that, of the AI enablers, acceptance of AI practices was significantly influenced by both technology roadmapping and attitude but not professional expertise. Of the AI readiness variables, acceptance of AI practices was significantly influenced by infrastructure and awareness but not technicality. The acceptance of AI practices was found to significantly affect AI-enabled relational governance and performance, and SME's business customer AI-based interaction. This study provides a broader base for theoretical and practical understanding of issues related to AI practices in SMEs and the B2B sector in general.","AI","University of Bristol"
"It's entrepreneurship, not enterprise: Ai Weiwei as entrepreneur: Ai Weiwei as entrepreneur","https://research-information.bris.ac.uk/en/publications/its-entrepreneurship-not-enterprise-ai-weiwei-as-entrepreneur-ai-","Hjorth, D.; Holt, R.","1 Jun 2016","We challenge the obvious and easy association of enterprise and entrepreneurship. We do so by arguing that entrepreneurship is inherently social and collective, something that is concealed when held up as example of enterprising behaviour. We use as an illustrative case the Chinese artist Ai Weiwei, an example of entrepreneurship that has little to do with commerce and everything to do with the social nature of creativity. We conclude by equating entrepreneurship to generosity: a social production of possibility from which all opportunities and ventures emerge.","AI","University of Bristol"
"La grande guida ai dinosauri","https://research-information.bris.ac.uk/en/publications/la-grande-guida-ai-dinosauri","Benton, MJ.","2002","None","AI","University of Bristol"
"AI, Automation, and New Socioeconomic Inequalities","https://research-information.bris.ac.uk/en/publications/ai-automation-and-new-socioeconomic-inequalities","Marston, G.; Zhang, J.","30 Jul 2019","Australia, similar to other advanced economies, has experienced rapid socio-technical change in recent years. There is a great deal of conjecture around this change and its impact on work and wellbeing. Issues related to the scope of technological unemployment, skills and retraining, and future demand for education and professionalization are hotly debated in the public realm. A key social justice question that emerges in the debate is whether or not the unprecedented pace of socio-technical changes associated with new forms of automation will lead to greater social or economic equality. While many commentators are optimistic that Artificial Intelligence (AI) and automation may create more leisure time, better quality work and more enriching lives, other caution that these technological advances may lead to a pooling of economic risk at the bottom of the income scale, with race, age, class and gender differences compounding employment precarity and existing patterns of disadvantage. The following discussion canvasses some of these risks and opportunities in regard to employment, public administration and representation. ","AI","University of Bristol"
"Clinical AI: opacity, accountability, responsibility and liability","https://research-information.bris.ac.uk/en/publications/clinical-ai-opacity-accountability-responsibility-and-liability","Smith, H.","25 Jul 2020","The aim of this literature review was to compose a narrative review supported by a systematic approach to critically identify and examine concerns about accountability and the allocation of responsibility and legal liability as applied to the clinician and the technologist as applied the use of opaque AI-powered systems in clinical decision making. This review questions (a) if it is permissible for a clinician to use an opaque AI system (AIS) in clinical decision making and (b) if a patient was harmed as a result of using a clinician using an AIS’s suggestion, how would responsibility and legal liability be allocated? Literature was systematically searched, retrieved, and reviewed from nine databases, which also included items from three clinical professional regulators, as well as relevant grey literature from governmental and non-governmental organisations. This literature was subjected to inclusion/exclusion criteria; those items found relevant to this review underwent data extraction. This review found that there are multiple concerns about opacity, accountability, responsibility and liability when considering the stakeholders of technologists and clinicians in the creation and use of AIS in clinical decision making. Accountability is challenged when the AIS used is opaque, and allocation of responsibility is somewhat unclear. Legal analysis would help stakeholders to understand their obligations and prepare should an undesirable scenario of patient harm eventuate when AIS were used.","AI","University of Bristol"
"Homer's Intelligent Machines: AI in Antiquity","https://research-information.bris.ac.uk/en/publications/homers-intelligent-machines-ai-in-antiquity","Samantha Thomas; Liveley, G.","2019","None","AI","University of Bristol"
"RC++: a rule-based language for game AI","https://research-information.bris.ac.uk/en/publications/rc-a-rule-based-language-for-game-ai","Ian, W.; James, M.","2000","""Game AI"" is the high-level control code for computer entertainment applications. Games are diverse, and the nature of game AI reflects this diversity. However, game AI, in contrast to rendering code and other game code, is distinguished by employing a high density of predicates on rapidly changing game state, and a high density of operations that change game state. Traditional programming languages, such as C and C++, are not designed to facilitate the creation of such code, unlike high-level AI rule-based languages. RC++, a full-featured, rule-based extension to C++, designed for Sony Computer Entertainment�s PlayStation2 hardware, is described. RC++ is based on OPS5 (Forgy, 81) and Poprulebase1, a rule-based extension to the Pop-11 programming language. It combines optimised execution associated with OPS5 with the syntactical style and some of the useful features of Poprulebase. It is designed to facilitate the rapid creation of game AI by automating many of the common programming tasks associated with creating game rules, while maintaining the flexibility of C and C++ when required. The aim of the paper is to demonstrate the applicability of rule-based programming to game AI in general, and the usefulness of RC++ for game AI in particular.    ","AI","University of Bristol"
"Dancing with the Troubles of AI","https://research-information.bris.ac.uk/en/publications/dancing-with-the-troubles-of-ai","Luján Escalante, M. A.; Moffat, L.; Harrison, L.; Kuh, V.","2021","None","AI","University of Bristol"
"Regulating Algorithmic Assemblages: Looking Beyond Corporatist AI Ethics","https://research-information.bris.ac.uk/en/publications/regulating-algorithmic-assemblages-looking-beyond-corporatist-ai-","Charlesworth, A. J.","1 Jul 2021","The perceived potential of artificial intelligence (AI) systems, broadly characterised, has seen a massive surge of investment in research and development, and their penetration into many decision-making processes of commercial, political and public organisations. Here, AI systems ubiquitously work behind the scenes to infuse decision-making processes with intelligence extracted from big data. This intelligence is used to develop highly personalised predictions or targeted services.  While the personalisation phenomenon can provide notable efficiencies and economic gains in delivering services, or allocating scarce state resources, it is also often accompanied by unintended negative effects. Media and academic accounts have focussed on the potential negative impacts on individuals or categories of individuals, but there has been much less consideration of broader consequences or ripple effects of incorporating AI into existing social systems. This chapter explores these consequences and ripple effects through an ‘AI ethics’ perspective, the dominant overarching discourse concerned with ‘regulating’ AI for the good of society. Yet ‘AI ethics’ is far removed from ‘AI law’ and is often presented as self-policing by private corporate actors in their use of AI systems, as sanctioned by government. The discussion critiques that self-policing, first, by locating AI ethics within long-standing traditions of corporate social responsibility and institutional ethical frameworks with all their in-built shortcomings, that frequently translate into a systemic inability to be truly Other-regarding. Second, this chapter shows, referencing the recent EU AI ethics initiative, that even well-intentioned initiatives may shoot past their target by simply assuming the desirability of AI applications, regardless of their wider impacts. Such an approach restricts itself to tinkering with system details whose consequences are relatively minor in comparison to the much broader impacts of AI within social systems, as captured by the idea of ‘algorithmic assemblage’.","AI","University of Bristol"
"Fuzzy Sets, Fuzzy Clustering and Fuzzy rules in AI","https://research-information.bris.ac.uk/en/publications/fuzzy-sets-fuzzy-clustering-and-fuzzy-rules-in-ai","Baldwin, JF.","1993","None","AI","University of Bristol"
"AI for Fundamental Rights at Work: Is the EC’s Proposal on a European Approach to AI up to it?","https://research-information.bris.ac.uk/en/publications/ai-for-fundamental-rights-at-work-is-the-ecs-proposal-on-a-europe","Novitz, T. A.","2021","None","AI","University of Bristol"
"The AI Question, or what if Homer had ChatGPT?","https://research-information.bris.ac.uk/en/publications/the-ai-question-or-what-if-homer-had-chatgpt","Cole, R. A.","1 Apr 2023","Since classical antiquity, there has been long-standing interest in the ‘Homeric Question’. This question covers several topics, most of which are related to the nature of authorship of the Iliad and the Odyssey. The Homeric Question focuses on who, exactly, Homer was, whether some of the most well-known epic poems of all time were the result of collaborative or single authorship, and under what circumstances the poems were composed and subsequently written down.The same questions can plausibly be asked of the works generated today by Artificial Intelligence (AI). Whether we are talking about a chapter inspired by the Harry Potter franchise, or the output of neural networks and text-generating bots, it remains unclear as to who, exactly, ‘wrote’ such works, whether they were composed by individuals or collectives, and indeed how such texts are produced in the first place. The similarities continue; just as the Homeric question focuses on the seismic developments surrounding the transition from oral to written culture, so AI-generated works ask us to reflect on what the transition from written to automated culture will involve, along with what impact this may have on the nature and reception of literature. My short paper will focus on this so-called ‘AI Question’. I will look at four examples of AI-powered authoring tools, from the simplest to the most advanced, and use the output of these tools to explore the way in which AI is contributing to a new form of literary culture. The aim is to consider how the questions asked of Homer can enhance our knowledge of AI-generated literature, as well as how AI-generated literature might in turn shed light on important transitions in the ancient world. This paper will begin by looking at the AI-powered keyboards created by Botnik. These keyboards can be pointed at any body of literature and will then suggest the next most likely word. In this paper, I will share the results of my experiments pointing Botnik’s keyboard at the works of Homer. As I will show, the simple Markov Chains behind the keyboard require a significant level of human input to generate epic poetry. In fact, it is virtually impossible to write epic poetry using these keyboards. Instead, the most logical outcome is to write absurdist poetry. Moving on to the neural network GPT-2, I then show how more advanced AI-tools can be tasked with suggesting entire phrases based on the first line of the Odyssey. While human choice is still important in determining which phrase is the most appropriate (or absurd), GPT-2 provides significantly greater input based on its training data, which includes a cross section of human literary output. Following GPT-2, I turn to Sudowrite, powered by the latest neural network GPT-3. Using Sudowrite, it is possible to ask the AI to generate an entire page of epic poetry based on the first line of the Odyssey. GPT-3’s output is perhaps the most coherent of the three, though appears prone to extensive plagiarism. However, it demonstrates the potential for AI to co-write anything from news reports to creative literature. Finally, I turn to InspiroBot and AI-generated inspirational phrases. These phrases come closest to the fantasy of AI authorship, not only in the sense that an AI appears to be writing independently of human input (all the human does is click a button), but also that the AI behind InspiroBot seems to understand motivational posters and quotes enough to be able to spoof them.Using these examples, I will argue that AI’s do not ‘author’ works so much provide endless variability inspired by existing formulas and ideas. The most creative work emerges at the intersection of human writers (or editors), and AI tools. By determining the contexts of a work, AI-powered writing tools are reminiscent of historical examples, such as the composition of the Homeric poems, when the possibility of a single, stable epic was far from certain, and when each performance remained in flux, caught between an individual’s creative input and a dataset of myths and formulations. ","AI","University of Bristol"
"Cybernetic animism: Voice and AI in conversation","https://research-information.bris.ac.uk/en/publications/cybernetic-animism-voice-and-ai-in-conversation","Allado-McDowell, K.; Bentivegna, F.","1 Aug 2022","This Voicing explores the theoretical and material connections between Artificial Intelligence (AI) and voice. The Voicing is in three-parts encompassing: a theoretical introduction with a taxonomy for voice and AI, an extract from artist K. Allado-McDowell’s new work Air Age Blueprint and an interview based on such text. Allado-McDowell pioneered the field of human–artificial intelligence interaction and literature. With their book Pharmako-AI, written in collaboration with GPT-3, Allado-McDowell stretched the limits of language creation. Francesco Bentivegna worked as artist in the liminal space of cyborgean voices and recently completed their Ph.D. on voice, AI and synthetic personas. As an exercise in philosophy of AI, voice studies and artistic research, Allado-McDowell and Bentivegna move in conversation through biases, vibes and language, exploring narrative, science and theory.","AI","University of Bristol"
"Fuzzy sets, fuzzy clustering and fuzzy rules in AI","https://research-information.bris.ac.uk/en/publications/fuzzy-sets-fuzzy-clustering-and-fuzzy-rules-in-ai-2","Baldwin, JF.","1994","None","AI","University of Bristol"
"AI anthropomorphism and its effect on users' self-congruence and self–AI integration: A theoretical framework and research agenda","https://research-information.bris.ac.uk/en/publications/ai-anthropomorphism-and-its-effect-on-users-self-congruence-and-s","Alabed, A.; Javornik, A.; Gregory-Smith, D.","Sept 2022","None","AI","University of Bristol"
"AI-Driven Innovation: Leveraging Big Data Analytics for Innovation","https://research-information.bris.ac.uk/en/publications/ai-driven-innovation-leveraging-big-data-analytics-for-innovation","Essien, A.","1 Jan 2023","Technological advancement and data ubiquity have resulted in the rapid and continuous development of data computing and processing tools, hardware, and software, which have impacted all facets of human endeavor. Artificial Intelligence (AI) is increasingly being applied in non-routine tasks that were earlier performed by humans alone. Despite the wave of AI in automation felt in other industries, the innovation sector is yet to feel a widespread adoption of AI in the innovation process. This chapter builds on existing literature to conceptualize the application of innovation analytics - referring to the application of AI-enabled, data-driven insights, algorithms, and visualizations within the innovation process. It is argued that AI has the potential to play a vital role in fostering innovation by driving key aspects within the innovation process. Using a hypothetical example of a tech start-up, we show an example of how infusing AI/big data analytics can serve as key enablers/triggers in the overall innovation process. Further, the chapter explicates the benefits and limitations of using AI in innovation and concludes by providing some implications of applying this technique in the innovation process.","AI","University of Bristol"
"Design support using distributed web-based AI tools","https://research-information.bris.ac.uk/en/publications/design-support-using-distributed-web-based-ai-tools","Rodgers, P. A.; Huxor, A. P.; Caldwell, N. H. M.","1 Jan 1999","Currently, designers are faced with searching through a `sea' of on-line knowledge to support their decision making activities. This paper describes WebCADET, which is a reimplementation of the stand-alone CADET - a Knowledge-Based System (KBS) for product design evaluation. Web-CADET aims to provide effective and efficient support for designers during their searches for design knowledge. WebCADET uses the `AI as text' approach, where KBSs can be seen as a medium to facilitate the communication of design knowledge between designers. The development of WebCADET to include practical support via World Wide Web-based functionality, which illustrates the potential of the `AI as text' approach, is described in the paper.","AI","University of Bristol"
"(De)troubling transparency: artificial intelligence (AI) for clinical applications","https://research-information.bris.ac.uk/en/publications/detroubling-transparency-artificial-intelligence-ai-for-clinical-","Winter, P.; Carusi, A.","11 May 2022","Artificial intelligence (AI) and machine learning (ML) techniques occupy a prominent role in medical research in terms of the innovation and development of new technologies. However, while many perceive AI as a technology of promise and hope—one that is allowing for more early and accurate diagnosis—the acceptance of AI and ML technologies in hospitals remains low. A major reason for this is the lack of transparency associated with these technologies, in particular epistemic transparency, which results in AI disturbing or troubling established knowledge practices in clinical contexts. In this article, we describe the development process of one AI application for a clinical setting. We show how epistemic transparency is negotiated and co-produced in close collaboration between AI developers and clinicians and biomedical scientists, forming the context in which AI is accepted as an epistemic operator. Drawing on qualitative research with collaborative researchers developing an AI technology for the early diagnosis of a rare respiratory disease (pulmonary hypertension/PH), this paper examines how including clinicians and clinical scientists in the collaborative practices of AI developers de-troubles transparency. Our research shows how de-troubling transparency occurs in three dimensions of AI development relating to PH: querying of data sets, building software and training the model. The close collaboration results in an AI application that is at once social and technological: it integrates and inscribes into the technology the knowledge processes of the different participants in its development. We suggest that it is a misnomer to call these applications ‘artificial’ intelligence, and that they would be better developed and implemented if they were reframed as forms of sociotechnical intelligence.","AI","University of Bristol"
"Detecting Bright Band using AI techniques in radar hydrology","https://research-information.bris.ac.uk/en/publications/detecting-bright-band-using-ai-techniques-in-radar-hydrology","Mcculloch, DR.; Lawry, J.; Rico-Ramirez, MA.; Cluckie, ID.","2007","http://www.cig.ensmp.fr/~iahs/redbooks/a316/iahs_316_0037.htm","AI","University of Bristol"
"Explainable AI for Non-Experts: Energy Tariff Forecasting","https://research-information.bris.ac.uk/en/publications/explainable-ai-for-non-experts-energy-tariff-forecasting-2","Ma, H.; McAreavey, K.; McConville, R.; Liu, W.","10 Oct 2022","Non-expert users are increasingly affected by the decisions of systems that rely on machine learning (ML), yet it is often difficult for these users to understand the predictions of ML models. In this paper, we propose a web-based platform to evaluate explainable AI (XAI) for non-experts in the context of time series forecasting, focusing on energy price predictions as an exemplary use case. The XAI methods we consider include local feature importance and counterfactual explanations. The platform relies on gamification to encourage user engagement. Our research objective is to evaluate the effectiveness of these different approaches from the perspective of non-expert under- standing of machine learning models.","AI","University of Bristol"
"Abduction and Induction in AI: Report of the IJCAI�97 workshop","https://research-information.bris.ac.uk/en/publications/abduction-and-induction-in-ai-report-of-the-ijcai97-workshop","Flach, P. A.; Kakas, A.","1998","None","AI","University of Bristol"
"AI-Enabled Large-Scale Entanglement Distribution Quantum Networks","https://research-information.bris.ac.uk/en/publications/ai-enabled-large-scale-entanglement-distribution-quantum-networks","Wang, R.; Joshi, S. K.; Kanellos, G.; Aktas, D. V.; Rarity, J. G.; Nejabati, R.; Simeonidou, D.","11 Jun 2021","We propose an entanglement distribution switching architecture to support large-scale dynamic quantum networking. Deep neural networks are further developed for predicting the performance of a dynamic entanglement distribution network utilizing the proposed architecture","AI","University of Bristol"
"Developing and Experimenting on Approaches to Explainability in AI Systems","https://research-information.bris.ac.uk/en/publications/developing-and-experimenting-on-approaches-to-explainability-in-a","Zhang, Y.; McAreavey, K.; Liu, W.","3 Feb 2022","There has been a sharp rise in research activities on explainable artificial intelligence (XAI), especially in the context of machine learning (ML). However, there has been less progress in developing and implementing XAI techniques in AI-enabled environments involving non-expert stakeholders. This paper reports our inves- tigations into providing explanations on the outcomes of ML algorithms to non-experts. We investigate the use of three explanation approaches (global, local, and counterfactual), considering decision trees as a use case ML model. We demonstrate the approaches with a sample dataset, and provide empirical results from a study involving over 200 participants. Our results show that most participants have a good understanding of the generated explanations.","AI","University of Bristol"
"Proceedings of the ECAI'98 Workshop on Abduction and Induction in AI","https://research-information.bris.ac.uk/en/publications/proceedings-of-the-ecai98-workshop-on-abduction-and-induction-in-","Flach, P. A.; Kakas, A.","1998","None","AI","University of Bristol"
"Proceedings of the ECAI'98 Workshop on Abduction and Induction in AI","https://research-information.bris.ac.uk/en/publications/proceedings-of-the-ecai98-workshop-on-abduction-and-induction-in-","Flach, P. A.; Kakas, A.","1998","None","AI","University of Bristol"
"Proceedings of the IJCAI'97 workshop on Abduction and Induction in AI","https://research-information.bris.ac.uk/en/publications/proceedings-of-the-ijcai97-workshop-on-abduction-and-induction-in","Flach, P. A.; Kakas, A.","1997","None","AI","University of Bristol"
"Methods Matter: A Trading Agent with No Intelligence Routinely Outperforms AI-Based Traders","https://research-information.bris.ac.uk/en/publications/methods-matter-a-trading-agent-with-no-intelligence-routinely-out","Cliff, D. T.; Rollins, M.","2 Dec 2020","There is a long tradition of research using computational intelligence, i.e. methods from artificial intelligence (AI) and machine learning (ML), to automatically discover, implement, and fine-tune strategies for autonomous adaptive automated trading in financial markets, with a sequence of research papers on this topic published at major AI conferences such as IJCAI and in prestigious journals such as Artificial Intelligence: we show evidence here that this strand of research has taken a number of methodological mis-steps and that actually some of the reportedly best-performing public-domain AI/ML trading strategies can routinely be out-performed by extremely simple trading strategies that involve no AI or ML at all. The results that we highlight here could easily have been revealed at the time that the relevant key papers were published, more than a decade ago, but the accepted methodology at the time of those publications involved a somewhat minimal approach to experimental evaluation of trader-agents, making claims on the basis of a few thousand test-sessions of the trader-agent in a small number of market scenarios. In this paper we present results from exhaustive testing over wide ranges of parameter values, using parallel cloud-computing facilities, where we conduct millions of tests and thereby create much richer data from which firmer conclusions can be drawn. We show that the best public-domain AI/ML traders in the published literature can be routinely outperformed by a ""sub-zero-intelligence"" trading strategy that at face value appears to be so simple as to be financially ruinous, but which interacts with the market in such a way that in practice it is more profitable than the well-known AI/ML strategies from the research literature. That such a simple strategy can outperform established AI/ML-based strategies is a sign that perhaps the AI/ML trading strategies were good answers to the wrong question.","AI","University of Bristol"
"Counterfactual explanations of machine learning predictions: Opportunities and challenges for AI safety","https://research-information.bris.ac.uk/en/publications/counterfactual-explanations-of-machine-learning-predictions-oppor","Sokol, K.; Flach, P.","27 Jan 2019","One necessary condition for creating a safe AI system is making it transparent to uncover any unintended or harmful behaviour. Transparency can be achieved by explaining predictions of an AI system with counterfactual statements, which are becoming a de facto standard in explaining algorithmic decisions. The popularity of counterfactuals is mainly attributed to their compliance with the “right to explanation” introduced by the European Union’s General Data Protection Regulation and them being understandable by a lay audience as well as domain experts. In this paper we describe our experience and the lessons learnt from explaining decision tree models trained on UCI German Credit and FICO Explainable Machine Learning Challenge data sets with class-contrastive counterfactual statements. We review how counterfactual explanations can affect an artificial intelligence system and its safety by investigating their risks and benefits. We show example explanations, discuss their strengths and weaknesses, show how they can be used to debug the underlying model, inspect its fairness and unveil security and privacy challenges that they pose.","AI","University of Bristol"
"Clinicians and AI use: Where is the professional guidance?","https://research-information.bris.ac.uk/en/publications/clinicians-and-ai-use-where-is-the-professional-guidance","Smith, H.; Downer, J. R.; Ives, J. C. S.","22 Aug 2023","With the introduction of artificial intelligence (AI) to healthcare, there is also a need for professional guidance to support its use. New (2022) reports from NHS AI Lab and Health Education England (HEE) focus on healthcare workers’ understanding and confidence in AI clinical decision support systems (AI-CDDSs), and are concerned with developing trust in, and the trustworthiness of these systems. While they offer guidance to aid developers and purchasers of such systems, however, they offer little specific guidance for the clinical users who will be required to use them in patient care.  This paper argues that clinical, professional, and reputational safety will be risked if this deficit of professional guidance for clinical users of AI-CDDSs is not redressed. We argue it is not enough to develop training for clinical users without first establishing professional guidance regarding the rights and expectations of clinical users. We conclude with a call to action for clinical regulators: to unite to draft guidance for users of AI-CDDS that helps manage clinical, professional, and reputational risks. We further suggest that this exercise offers an opportunity to address fundamental issues in the use of AI-CDDSs; regarding, for example, the fair burden of responsibility for outcomes. ","AI","University of Bristol"
"A Toolkit of Dilemmas: Beyond debiasing and fairness formulas for responsible AI/ML","https://research-information.bris.ac.uk/en/publications/a-toolkit-of-dilemmas-beyond-debiasing-and-fairness-formulas-for-","Domínguez Hernández, A.; Galanos, V.","28 Aug 2023","Approaches to fair and ethical AI have recently fell under the scrutiny of the emerging, chiefly qualitative, field of critical data studies, placing emphasis on the lack of sensitivity to context and complex social phenomena of such interventions. We employ some of these lessons to introduce a tripartite decision-making toolkit, informed by dilemmas encountered in the pursuit of responsible AI/ML. These are: (a) the opportunity dilemma between the availability of data shaping problem statements vs problem statements shaping data; (b) the trade-off between scalability and contextualizability (too much data versus too specific data); and (c) the epistemic positioning between the pragmatic technical objectivism and the reflexive relativism in acknowledging the social. This paper advocates for a situated reasoning and creative engagement with the dilemmas surrounding responsible algorithmic/data-driven systems, and going beyond the formulaic bias elimination and ethics operationalization narratives found in the fair-AI literature.  ","AI","University of Bristol"
"Normative Ethics Principles for Responsible AI Systems: Taxonomy and Future Directions","https://research-information.bris.ac.uk/en/publications/normative-ethics-principles-for-responsible-ai-systems-taxonomy-a","Woodgate, J.; Ajmeri, N.","12 Aug 2022","The rapid adoption of artificial intelligence (AI) necessitates careful analysis of its ethical implications. In addressing ethics and fairness implications, it is important to examine the whole range of ethically relevant features rather than looking at individual agents alone. This can be accomplished by shifting perspective to the systems in which agents are embedded, which is encapsulated in the macro ethics of sociotechnical systems (STS). Through the lens of macro ethics, the governance of systems - which is where participants try to promote outcomes and norms which reflect their values - is key. However, multiple-user social dilemmas arise in an STS when stakeholders of the STS have different value preferences or when norms in the STS conflict. To develop equitable governance which meets the needs of different stakeholders, and resolve these dilemmas in satisfactory ways with a higher goal of fairness, we need to integrate a variety of normative ethical principles in reasoning. Normative ethical principles are understood as operationalizable rules inferred from philosophical theories. A taxonomy of ethical principles is thus beneficial to enable practitioners to utilise them in reasoning. This work develops a taxonomy of normative ethical principles which can be operationalized in the governance of STS. We identify an array of ethical principles, with 25 nodes on the taxonomy tree. We describe the ways in which each principle has previously been operationalized, and suggest how the operationalization of principles may be applied to the macro ethics of STS. We further explain potential difficulties that may arise with each principle. We envision this taxonomy will facilitate the development of methodologies to incorporate ethical principles in reasoning capacities for governing equitable STS.","AI","University of Bristol"
"The influence of AI text generators on critical thinking skills in UK business schools","https://research-information.bris.ac.uk/en/publications/the-influence-of-ai-text-generators-on-critical-thinking-skills-i","Essien, A. E.; Bukoye, O.; O'Dea, C.; Kremantzis, M. D.","17 Feb 2024","This study investigates the influence of generative artificial intelligence (GAI), specifically AI text generators (ChatGPT), on critical thinking skills in UK postgraduate business school students. Using Bloom’s taxonomy as theoretical underpinning, we adopt a mixed-method research employing a sample of 107 participants to investigate both the influence and challenges of these technologies in higher education. Our findings reveal that the most significant improvements occurred at the lower levels of Bloom’s taxonomy. We identify concerns relating to reliability, accuracy, and potential ethical implications of its application in higher education. The significance of this paper spans across, pedagogy, policy and practice, offering insights into the complex relationship between AI technologies and critical thinking skills. While highlighting  the multifaceted aspects of the impact of AI in education, this article serves as a guide to educators and policymakers, stressing the importance of a comprehensive approach to fostering critical thinking and other transferable skills in the higher education landscape.","AI","University of Bristol"
"""Future Directions for Soft Computing"" in Computational Intelligence - Towards Convergence of Soft Computing and AI","https://research-information.bris.ac.uk/en/publications/future-directions-for-soft-computing-in-computational-intelligenc","Baldwin, JF.","2000","None","AI","University of Bristol"
"Integrating Artificial Intelligence in Scientific Practice: Explicable AI as an Interface","https://research-information.bris.ac.uk/en/publications/integrating-artificial-intelligence-in-scientific-practice-explic","Ratti, E.","30 Jun 2022","A recent article by Herzog provides a much-needed integration of ethical and epistemological arguments in favor of explicable AI (XAI) in medicine. In this short piece, I suggest a way in which its epistemological intuition of XAI as “explanatory interface” can be further developed to delineate the relation between AI tools and scientific research.","AI","University of Bristol"
"Explainable machine learning practices: opening another black box for reliable medical AI","https://research-information.bris.ac.uk/en/publications/explainable-machine-learning-practices-opening-another-black-box-","Ratti, E.; Graves, M.","Nov 2022","In the past few years, machine learning (ML) tools have been implemented with success in the medical context. However, several practitioners have raised concerns about the lack of transparency—at the algorithmic level—of many of these tools; and solutions from the field of explainable AI (XAI) have been seen as a way to open the ‘black box’ and make the tools more trustworthy. Recently, Alex London has argued that in the medical context we do not need machine learning tools to be interpretable at the algorithmic level to make them trustworthy, as long as they meet some strict empirical desiderata. In this paper, we analyse and develop London’s position. In particular, we make two claims. First, we claim that London’s solution to the problem of trust can potentially address another problem, which is how to evaluate the reliability of ML tools in medicine for regulatory purposes. Second, we claim that to deal with this problem, we need to develop London’s views by shifting the focus from the opacity of algorithmic details to the opacity of the way in which ML tools are trained and built. We claim that to regulate AI tools and evaluate their reliability, agencies need an explanation of how ML tools have been built, which requires documenting and justifying the technical choices that practitioners have made in designing such tools. This is because different algorithmic designs may lead to different outcomes, and to the realization of different purposes. However, given that technical choices underlying algorithmic design are shaped by value-laden considerations, opening the black box of the design process means also making transparent and motivating (technical and ethical) values and preferences behind such choices. Using tools from philosophy of technology and philosophy of science, we elaborate a framework showing how an explanation of the training processes of ML tools in medicine should look like.","AI","University of Bristol"
"Field-Trial Demonstration of ML Deployment in Optical Networks Using Telemetry and AI Engine","https://research-information.bris.ac.uk/en/publications/field-trial-demonstration-of-ml-deployment-in-optical-networks-us","Shen, S.; Yang, R.; Li, H.; Teng, Y.; Wang, R.; Nejabati, R.; Yan, S.; Simeonidou, D.","6 Jul 2023","We present an AI engine built on OpenFaas utilizing distributed databases and network telemetry to monitor and manage multiple ML models. Two use cases of ML applications in optical networks are demonstrated over the field-trial testbed, showcasing the feasibility and scalability of the proposed scheme.","AI","University of Bristol"
"The Political Space of Art: The Dardenne Brothers, Ai Weiwei, Arundhati Roy and Burial","https://research-information.bris.ac.uk/en/publications/the-political-space-of-art-the-dardenne-brothers-ai-weiwei-arundh","Dillet, B.; Puri, T.","1 Dec 2015","This book studies the tension between arts and politics in four contemporary artists from different countries, working with different media. The film directors Luc and Jean-Pierre Dardenne film parts of their natal city to refer to specific political problems in interpersonal relations. Ai Weiwei uses references to Chinese history to give consistency to its economic miracle . Burial s electronic music is firmly rooted in a living, breathing London; built to create a sound that is entirely new, and yet hauntingly familiar. Finally, the novelist Arundhati Roy uses her poetic language to make room for people s desires; her fiction is utterly political and her political essays make place for the role of narratives and poetic language.These artists create in their own way a space for politics in their works and their oeuvre but their singularity comes together as a desire to reconstruct the political space within art from its ruins. These ruins were brought by the disenchantment of 1970s: the end of art, postmodernism, and the rise of design, marketing and communication. Each artwork bears the mark of the resistance against the depoliticisation of society and the arts, at once rejecting cynicism and idealism, referring to themes and political concepts that are larger than their own domain. This book focuses on these productive tensions.","AI","University of Bristol"
"Adaptable Robots, Ethics, and Trust: A Qualitative and Philosophical Exploration of the Individual Experience of Trustworthy AI","https://research-information.bris.ac.uk/en/publications/adaptable-robots-ethics-and-trust-a-qualitative-and-philosophical","Sheir, S.; Manzini, A.; Smith, H.; Ives, J. C. S.","18 Mar 2024","Much has been written about the need for trustworthy artificial intelligence (AI), but the underlying meaning of trust and trustworthiness can vary or be used in confusing ways. It is not always clear whether individuals are speaking of a technology’s trustworthiness, a developer’s trustworthiness, or simply of gaining the trust of users by any means. In sociotechnical circles, trustworthiness is often used as a proxy for ‘the good’, illustrating the moral heights to which technologies and developers ought to aspire, at times with a multitude of diverse requirements; or at other times, no specification at all. In philosophical circles, there is doubt that the concept of trust should be applied at all to technologies rather than their human creators. Nevertheless, people continue to intuitively reason about trust in technologies in their everyday language. This qualitative study employed an empirical ethics methodology to address how developers and users define and construct requirements for trust throughout development and use, through a series of interviews. We found that different accounts of trust (rational, affective, credentialist, norms-based, relational) served as the basis for individual granting of trust in technologies and operators. Ultimately, the most significant requirement for user trust and assessment of trustworthiness was the accountability of AI developers for the outputs of AI systems, hinging on the identification of accountable moral agents and perceived value alignment between the user and developer’s interests. ","AI","University of Bristol"
"How AI and AR could increase the risk of problem gambling for online sports betting","https://research-information.bris.ac.uk/en/publications/how-ai-and-ar-could-increase-the-risk-of-problem-gambling-for-onl","Newall, P. W. S.; Torrance, J.","25 Sept 2023","None","AI","University of Bristol"
"Consumer Engagement with AI-Powered Voice Assistants: A behavioral reasoning perspective","https://research-information.bris.ac.uk/en/publications/consumer-engagement-with-ai-powered-voice-assistants-a-behavioral","Acikgoz, F.; Perez-Vega, R.; Okumus, F.; Stylos, N.","3 Oct 2023","This study draws upon Behavioral Reasoning Theory and the Technology Acceptance Model to investigate consumer engagement with AI-powered voice assistants. The study creates a theoretical model to examine the effects of reasons for and reasons against using voice assistants. This research exemplifies attitudes towards using voice assistants and willingness to provide personal information as key constructs. The current study tests data from 491 voice assistant users via mTurk, and we utilize a multimethod analysis scheme including the partial least squares technique and the fuzzy set qualitative comparative analysis approach to provide an assessment of the proposed model. Findings indicated that while privacy cynicism has a negative impact upon the attitude towards using voice assistants, the countervailing values of trust, perceived usefulness, and ease of use have off-setting positive impact. The study also highlights the moderating role of habit on the behavioral mechanisms driving consumer engagement via willingness to provide privacy information. This research advances the emerging literature on voice assistants with respect to privacy-related factors driving consumer engagement.","AI","University of Bristol"
"Standards for Test Sets Used in AI Studies: A Rapid Review","https://research-information.bris.ac.uk/en/publications/standards-for-test-sets-used-in-ai-studies-a-rapid-review","Shokraneh, F.; Chalkidou, A.; Seedat, F.; Kijauskaite, G.","30 Aug 2022","None","AI","University of Bristol"
"Evaluating contrastive explanations for AI planning with non-experts: a smart home battery scenario","https://research-information.bris.ac.uk/en/publications/evaluating-contrastive-explanations-for-ai-planning-with-non-expe","Shi, Y.; McAreavey, K.; Liu, W.","10 Oct 2022","Smart home systems with AI planning functionality have the potential to improve the lives of users. However, there is an emerging expectation that users should better understand and trust the decision-making of AI systems. In this paper, asmart home battery system is developed with a supplementary explanation module that allows non-expert users to intuitively visualise the planning process and to better understand its recommendations. The module relies on a notion of contrastive explanations, related to iterative planning, allowing users to ask contrastive questions based on state- and action-constraints that may or may not be satisfiable. The system is intended for an experimental study where participants interact with the planning system and complete a questionnaire, with the research objective being to evaluate the usefulness of the explanation module.","AI","University of Bristol"
"Response to the UK’s March 2023 White Paper ""A pro-innovation approach to AI regulation""","https://research-information.bris.ac.uk/en/publications/response-to-the-uks-march-2023-white-paper-a-pro-innovation-appro","Charlesworth, A. J.; Fotheringham, K.; Gavaghan, C.; Sanchez-Graells, A.; Torrible, C. N.","19 Jun 2023","Here, we provide a response to the UK Government's March 2023 white paper ""A pro-innovation approach to AI regulation"". We challenge the white paper's claims that it puts forward a balanced, pragmatic, proportionate, contextualised, and agile model that leverages the capabilities and skills of existing regulators to foster AI innovation. We also challenge the claims that the model is underpinned by a set of principles providing a clear, unified, and flexible framework that improves upon the current ‘complex patchwork of legal requirements’.","AI","University of Bristol"
"Machine Learning Explanations as Boundary Objects: How AI Researchers Explain and Non-Experts Perceive Machine Learning","https://research-information.bris.ac.uk/en/publications/machine-learning-explanations-as-boundary-objects-how-ai-research","Ayobi, A.; Stawarz, K.; Katz, D.; Marshall, P.; Yamagata, T.; Santos-Rodriguez, R.; Flach, P. A.","17 Apr 2021","Understanding artificial intelligence (AI) and machine learning (ML) approaches is becoming increasingly important for people with a wide range of professional backgrounds. However, it is unclear how ML concepts can be effectively explained as part of human-centred and multidisciplinary design processes. We provide a qualitative account of how AI researchers explained and non-experts perceived ML concepts as part of a co-design project that aimed to inform the design of ML applications for diabetes self-care. We identify benefits and challenges of explaining ML concepts with analogical narratives, information visualisations, and publicly available videos. Co-design participants reported not only gaining an improved understanding of ML concepts but also highlighted challenges of understanding ML explanations, including misalignments between scientific models and their lived self-care experiences and individual information needs. We frame our findings through the lens of Stars and Griesemer’s concept of boundary objects to discuss how the presentation of user-centred ML explanations could strike a balance between being plastic and robust enough to support design objectives and people’s individual information needs.","AI","University of Bristol"
"On-line Monitoring of Weather Radar Antenna Pointing using high-resolution DTM and AI techniques","https://research-information.bris.ac.uk/en/publications/on-line-monitoring-of-weather-radar-antenna-pointing-using-high-r","Rico-Ramirez, MA.; Gonzalez-Ramirez, E.; Cluckie, ID.","2008","This paper presents a novel tecnique to continuously monitor the azimuthal pointing accuracy of a weather radar antenna.  The technique consists in cross correlating modeled and measured echoes from ground clutter in real-time at low elevation angles in precipitation and non-precipitation conditions. The azimuthal angle with maximum cross-correlation indicates the adjustment in antenna pointing accuracy.  The modeled ground clutter echoes are obtained using high-resolution digital terrain elevation (DTM) data whereas the measured ground clutter echoes can be obtained in real-time by using a Bayes classifier, which identifies the clutter echoes in the presence of precipitation.","AI","University of Bristol"
"Toward AI-Enabled NextG Networks with Edge Intelligence-Assisted Microservice Orchestration","https://research-information.bris.ac.uk/en/publications/toward-ai-enabled-nextg-networks-with-edge-intelligence-assisted-","Zeb, S.; Rathore, M. A.; Hassan, S. A.; Raza, S.; Dev, K.; Fortino, G.","Jun 2023","None","AI","University of Bristol"
"Generative AI And the Automating of Academia","https://research-information.bris.ac.uk/en/publications/generative-ai-and-the-automating-of-academia","Watermeyer, R. P.; Phipps, L.; Lanclos, D.; Knight, C.","6 Nov 2023","The neoliberal transformation of higher education in the UK and an intertwined focus on the productive efficiency and prestige value of universities has led to an epidemic of overwork and precarity among academics. Many are found to be struggling with lofty performance expectations and an insistence that all dimensions of their work consistently achieve positional gains despite ferocious competition and the omnipresent threat of failure. Working under the current audit culture present across education, academics are thus found to overwork or commit to accelerated labour as pre-emptive compensation for the habitual inclemency of peer-review and vagaries of student evaluation, in accommodating the copiousness of ‘invisible’ tasks, and in eluding the myriad crevasses of their precarious labour. The proliferation of generative artificial intelligence (GAI) tools and more specifically, Large Language Models (LLMs) like ChatGPT, offers potential relief for academics and a means to offset intensive demands and discover more of a work-based equilibrium. Through a recent survey of n=284 UK academics and their use of GAI, we discover, however, that the digitalisation of higher education through GAI tools no more alleviates than extends the dysfunctions of neoliberal logic and deepens academia’s malaise. Notwithstanding, we argue that the proliferating use of GAI tools by academics may be harnessed as a source of positive disruption to the industrialisation of their labour and catalyst of (re)engagement with scholarly craftsmanship.","AI","University of Bristol"
"Glass-Box: Explaining AI Decisions With Counterfactual Statements Through Conversation With a Voice-enabled Virtual Assistant.","https://research-information.bris.ac.uk/en/publications/glass-box-explaining-ai-decisions-with-counterfactual-statements-","Sokol, K.; Flach, P. A.","13 Jul 2018","None","AI","University of Bristol"
"AI Slipping on Tiles: Data Leakage in Digital Pathology","https://research-information.bris.ac.uk/en/publications/ai-slipping-on-tiles-data-leakage-in-digital-pathology","Bussola, N.; Marcolini, A.; Maggio, V.; Jurman, G.; Furlanello, C.","21 Feb 2021","None","AI","University of Bristol"
"Glass-Box: Explaining AI Decisions With Counterfactual Statements Through Conversation With a Voice-enabled Virtual Assistant.","https://research-information.bris.ac.uk/en/publications/glass-box-explaining-ai-decisions-with-counterfactual-statements-","Sokol, K.; Flach, P. A.","13 Jul 2018","None","AI","University of Bristol"
"Generative AI And the Automating of Academia","https://research-information.bris.ac.uk/en/publications/generative-ai-and-the-automating-of-academia","Watermeyer, R. P.; Phipps, L.; Lanclos, D.; Knight, C.","6 Nov 2023","The neoliberal transformation of higher education in the UK and an intertwined focus on the productive efficiency and prestige value of universities has led to an epidemic of overwork and precarity among academics. Many are found to be struggling with lofty performance expectations and an insistence that all dimensions of their work consistently achieve positional gains despite ferocious competition and the omnipresent threat of failure. Working under the current audit culture present across education, academics are thus found to overwork or commit to accelerated labour as pre-emptive compensation for the habitual inclemency of peer-review and vagaries of student evaluation, in accommodating the copiousness of ‘invisible’ tasks, and in eluding the myriad crevasses of their precarious labour. The proliferation of generative artificial intelligence (GAI) tools and more specifically, Large Language Models (LLMs) like ChatGPT, offers potential relief for academics and a means to offset intensive demands and discover more of a work-based equilibrium. Through a recent survey of n=284 UK academics and their use of GAI, we discover, however, that the digitalisation of higher education through GAI tools no more alleviates than extends the dysfunctions of neoliberal logic and deepens academia’s malaise. Notwithstanding, we argue that the proliferating use of GAI tools by academics may be harnessed as a source of positive disruption to the industrialisation of their labour and catalyst of (re)engagement with scholarly craftsmanship.","AI","University of Bristol"
"Data Ethics Emergency Drill: A Toolbox for Discussing Responsible AI for Industry Teams","https://research-information.bris.ac.uk/en/publications/data-ethics-emergency-drill-a-toolbox-for-discussing-responsible-","Hanschke, V. A.; Rees, D.; Alanyali, M.; Hopkinson, D.; Marshall, P.","12 Mar 2024","Researchers urge technology practitioners such as data scientists to consider the impacts and ethical implications of algorithmic decisions. However, unlike programming, statistics, and data management, discussion of ethical implications is rarely included in standard data science training. To begin to address this gap, we designed and tested a toolbox called the data ethics emergency drill (DEED) to help data science teams discuss and reflect on the ethical implications of their work. The DEED is a roleplay of a fictional ethical emergency scenario that is contextually situated in the team’s specific workplace and applications. This paper outlines the DEED toolbox and describes three studies carried out with two different data science teams that iteratively shaped its design. Our findings show that practitioners can apply lessons learnt from the roleplay to real-life situations, and how the DEED opened up conversations around ethics and values.","AI","University of Bristol"
"Resh(AI)ping Good Administration: Addressing the mass effects of public sector digitalisation","https://research-information.bris.ac.uk/en/publications/reshaiping-good-administration-addressing-the-mass-effects-of-pub","Sanchez-Graells, A.","16 Feb 2024","Public sector digitalisation is transforming public governance at an accelerating rate. Digitalisation is outpacing the evolution of the legal framework. Despite several strands of international efforts to adjust good administration guarantees to new modes of digital public governance, progress has so far been slow and tepid. The increasing automation of decision-making processes puts significant pressure on traditional good administration guarantees, jeopardises individual due process rights, and risks eroding public trust. Automated decision-making has so far attracted the bulk of scholarly attention, especially in the European context. However, most analyses seek to reconcile existing duties towards individuals under the right to good administration with the challenges arising from digitalisation. Taking a critical and technology-centred doctrinal approach to developments under the law of the European Union and the Council of Europe, this paper goes beyond current debates to challenge the sufficiency of existing good administration duties. By stressing the mass effects that can derive from automated decision-making by the public sector, the paper advances the need to adapt good administration guarantees to a collective dimension through an extension and a broadening of the public sector’s good administration duties: that is, through an extended ex ante control of or-ganisational risk-taking, and a broader ex post duty of automated redress. These legal modifications should be urgently implemented.","AI","University of Bristol"
"Professional expectations and patient expectations concerning the development of Artificial Intelligence (AI) for the early diagnosis of Pulmonary Hypertension (PH)","https://research-information.bris.ac.uk/en/publications/professional-expectations-and-patient-expectations-concerning-the","Winter, P.; Carusi, A.","Dec 2022","The expectations of professionals working on the development of healthcare Artificial Intelligence (AI) technologies and the patients who will be affected by them have received limited attention. This paper reports on a Foresight Workshop with professionals involved with pulmonary hypertension (PH) and a Focus Group with members of a PH patient group, to discuss expectations of AI development and implementation. We show that while professionals and patients had similar expectations of AI, with respect to the priority of early diagnosis; data risks of privacy and reuse; and responsibility, other expectations differed. One important point of difference was in the attitude toward using AI to point up other potential health problems (in addition to PH). A second difference was in the expectations regarding how much clinical professionals should know about the role of AI in diagnosis. These findings allow us to better prepare for the future by providing a frank appraisal of the complexities of AI development with foresight, and the anxieties of key stakeholders.","AI","University of Bristol"
"Use of deterministic AI and a multi-user virtual test environment for drone inspection mission safety","https://research-information.bris.ac.uk/en/publications/use-of-deterministic-ai-and-a-multi-user-virtual-test-environment","Goudarzi, H.; Marsh, C.; Richards, A. G.; Crowther, W.; Parslew, B.","2022","One of the major challenges of integrating AI in UAV control is the ability of the pilot to effectively interact with the system. Inspired by process-control and vigilance devices, this work employs a predictable and deterministic form of AI to enable single-crew (i.e. pilot) operation in an unconstrained dynamic environment. A multi-user simulation environment was developed in Unity to validate the mission and to train and evaluate pilot-automation interactions. Preliminary simulation results for an inspection case study at the Clifton Suspension Bridge are reported.","AI","University of Bristol"
"Field Trial Demonstration of AI-Engine Driven Cross-Domain Rerouting and Optimisation in Dynamic Optical Networks","https://research-information.bris.ac.uk/en/publications/field-trial-demonstration-of-ai-engine-driven-cross-domain-rerout","Yang, M.; Li, O.; Teng, Y.; Shen, S.; Wang, R.; Oliveira, R. D.; Nejabati, R.; Yan, S.; Simeonidou, D.","5 Oct 2023","An AI-engine-driven cross-domain orchestrator has been implemented on a multi-domain field trial testbed with demonstrations of deploying end-to-end services with a 20% improvement in BER performance, enabled by the developed flex-grid multi-channel QoT prediction, and rerouting network traffic jointly to avoid link failure within 800ms.","AI","University of Bristol"
"A Dempster–Shafer model of imprecise assertion strategies: Workshop on Weighted Logics for AI - 2013","https://research-information.bris.ac.uk/en/publications/a-dempstershafer-model-of-imprecise-assertion-strategies-workshop","Eyre, H.; Lawry, J.","Dec 2015","A Dempster–Shafer theory based model of assertion is proposed for multi-agent communications so as to capture both epistemic and strategic uncertainty. Treating assertion as a choice problem, we argue that for complex multi-agent communication systems, individual agents will only tend to have sufficient information to allow them to formulate imprecise strategies for choosing between different possible true assertions. In a propositional logic setting, an imprecise assertion strategy is defined as a functional mapping between a valuation and a set of true sentences, where the latter is assumed to contain the optimal assertion given that particular state of the world. Uncertainty is then quantified in terms of probability distributions defined on the joint space of valuations and strategies, naturally leading to Dempster–Shafer belief and plausibility measures on sets of possible assertions. This model is extended so as to include imprecise valuations and to provide a meta-level treatment of weak and strong assertions. As a case study, we consider the application of our proposed assertion models to the problem of choosing between a number of different vague descriptions, in the context of both epistemic and supervaluationist approaches to vagueness.","AI","University of Bristol"
"More than just a chat: a taxonomy of consumers’ relationships with conversational AI agents and their well-being implications","https://research-information.bris.ac.uk/en/publications/more-than-just-a-chat-a-taxonomy-of-consumers-relationships-with-","Alabed, A.; Javornik, A.; Gregory-Smith, D.; Casey, R.","8 Feb 2024","Purpose: This paper aims to study the role of self-concept in consumer relationships with anthropomorphised conversational artificially intelligent (AI) agents. First, the authors investigate how the self-congruence between consumer self-concept and AI and the integration of the conversational AI agent into consumer self-concept might influence such relationships. Second, the authors examine whether these links with self-concept have implications for mental well-being. Design/methodology/approach: This study conducted in-depth interviews with 20 consumers who regularly use popular conversational AI agents for functional or emotional tasks. Based on a thematic analysis and an ideal-type analysis, this study derived a taxonomy of consumer–AI relationships, with self-congruence and self–AI integration as the two axes. Findings: The findings unveil four different relationships that consumers forge with their conversational AI agents, which differ in self-congruence and self–AI integration. Both dimensions are prominent in replacement and committed relationships, where consumers rely on conversational AI agents for companionship and emotional tasks such as personal growth or as a means for overcoming past traumas. These two relationships carry well-being risks in terms of changing expectations that consumers seek to fulfil in human-to-human relationships. Conversely, in the functional relationship, the conversational AI agents are viewed as an important part of one’s professional performance; however, consumers maintain a low sense of self-congruence and distinguish themselves from the agent, also because of the fear of losing their sense of uniqueness and autonomy. Consumers in aspiring relationships rely on their agents for companionship to remedy social exclusion and loneliness, but feel this is prevented because of the agents’ technical limitations. Research limitations/implications: Although this study provides insights into the dynamics of consumer relationships with conversational AI agents, it comes with limitations. The sample of this study included users of conversational AI agents such as Siri, Google Assistant and Replika. However, future studies should also investigate other agents, such as ChatGPT. Moreover, the self-related processes studied here could be compared across public and private contexts. There is also a need to examine such complex relationships with longitudinal studies. Moreover, future research should explore how consumers’ self-concept could be negatively affected if the support provided by AI is withdrawn. Finally, this study reveals that in some cases, consumers are changing their expectations related to human-to-human relationships based on their interactions with conversational AI agents. Practical implications: This study enables practitioners to identify specific anthropomorphic cues that can support the development of different types of consumer–AI relationships and to consider their consequences across a range of well-being aspects. Originality/value: This research equips marketing scholars with a novel understanding of the role of self-concept in the relationships that consumers forge with popular conversational AI agents and the associated well-being implications.","AI","University of Bristol"
"What Could Models of Superorganismal Cognition Offer to Embodied AI?","https://research-information.bris.ac.uk/en/publications/what-could-models-of-superorganismal-cognition-offer-to-embodied-","Hunt, E. R.","10 Oct 2022","Superorganisms such as ant or honeybee colonies exhibit extraordinary collective intelligence, such as an ability to identify and choose the best available nest site in an uncertain world. This collective cognition is inextricably reliant on the embodiment of individual agents, specifically their movement through space. We have recently developed models of superorganismal cognition based on a compelling analogy with techniques in Bayesian statistics, which are likewise aimed at grappling with the uncertainty and incompleteness of real data sources. These models foreground some potential lessons for the design of embodied artificial intelligences, such as robot swarms. For example, the spatial distribution of independently judging agents can convey valuable information, relaxing expectations that regular inter-agent ('inter-neuronal') communication is necessary for cognition, which points to the potential of minimal field swarm robotics. Meanwhile, the importance of individual heterogeneity to effective and resilient collective cognition in biology suggests great potential in this area for engineering.","AI","University of Bristol"
"AI slipping on tiles: data leakage in digital pathology","https://research-information.bris.ac.uk/en/publications/ai-slipping-on-tiles-data-leakage-in-digital-pathology-2","Bussola, N.; Marcolini, A.; Maggio, V.; Jurman, G.; Furlanello, C.","21 Feb 2021","Reproducibility of AI models on biomedical data still stays as a major concern for their acceptance into the clinical practice. Initiatives for reproducibility in the development of predictive biomarkers as the MAQC Consortium already underlined the importance of appropriate Data Analysis Plans (DAPs) to control for different types of bias, including data leakage from the training to the test set. In the context of digital pathology, the leakage typically lurks in weakly designed experiments not accounting for the subjects in their data partitioning schemes. This issue is then exacerbated when fractions or subregions of slides (i.e. ""tiles"") are considered. Despite this aspect is largely recognized by the community, we argue that it is often overlooked. In this study, we assess the impact of data leakage on the performance of machine learning models trained and validated on multiple histology data collection. We prove that, even with a properly designed DAP (10x5 repeated cross-validation), predictive scores can be inflated up to 41% when tiles from the same subject are used both in training and validation sets by deep learning models. We replicate the experiments for $4$ classification tasks on 3 histopathological datasets, for a total of 374 subjects, 556 slides and more than 27,000 tiles. Also, we discuss the effects of data leakage on transfer learning strategies with models pre-trained on general-purpose datasets or off-task digital pathology collections. Finally, we propose a solution that automates the creation of leakage-free deep learning pipelines for digital pathology based on histolab, a novel Python package for histology data preprocessing. We validate the solution on two public datasets (TCGA and GTEx).","AI","University of Bristol"
"Using Artificial Intelligence (AI)-interfaced robotic toys in early childhood settings: a case for children’s inquiry literacy: a case for children’s inquiry literacy","https://research-information.bris.ac.uk/en/publications/using-artificial-intelligence-ai-interfaced-robotic-toys-in-early","Kewalramani, S.; Kidman, G.; Palaiologou, I.","26 Aug 2021","This study explores the use of interactive Artificial Intelligence (AI)-interfaced robotic toys within early childhood (EC) settings to develop children’s inquiry literacy. Arguments about the appropriate role of AI in EC education have received much attention when examining the potential of the integration of technology into children’s play and learning. Using Vygotsky’s mediation theory (1978) and employing a design-based research methodology, teachers intentionally used AI robotic toys to engage children (4–5 years old) during play experiences. The data from both teachers’ and children’s interviews, observations and artefact analysis revealed how children creatively collaborated with their peers to create a sustainable city for their robot and ‘his’ family to live happily. Children’s play with the AI robot fostered inquiry literacies–namely creative inquiry, emotional inquiry and collaborative inquiry. This study contributes to research by exploring the use of AI toys together with physical and artificial environments and offers a case to shape children’s inquiry literacies. Implications lie in upskilling EC teachers to provide opportunities to play with AI-interfaced robotic toys to foster children’s inquiry literacy development process.","AI","University of Bristol"
"Reporting guideline for the early stage clinical evaluation of decision support systems driven by artificial intelligence: DECIDE-AI","https://research-information.bris.ac.uk/en/publications/reporting-guideline-for-the-early-stage-clinical-evaluation-of-de-2"," & 4 others; Weber, W.; Wheatstone, P.; McCulloch, P.; DECIDE-AI expert group","18 May 2022","None","AI","University of Bristol"
"""Ai, que em faig un lio"": Desenvolupaments recents del coneixement de les normatives lingüístiques catalana i castellana.","https://research-information.bris.ac.uk/en/publications/ai-que-em-faig-un-lio-desenvolupaments-recents-del-coneixement-de","Hawkey, J. W.","2014","L’article examina el coneixement de les varietats normatives del català i del castellà, mitjançant un experiment de camp innovador. Uns cinquanta participants van haver de reconèixer casos d'interferència lingüística, i a partir dels resultats, va ser possible avaluar els seus nivells de coneixement de la normativa lingüística vigent. Els participants provenien de dos grups d’edat. Els més joves tenien entre 25 i 35 anys i els més grans entre 55 i 65. El marc teòric de l'article es focalitza en el debat acadèmic sobre la planificació i la política lingüística, i sobretot en la planificació del corpus i la codificació de la llengua, ja que l’experiment examina el paper de la interferència en la llengua normativa. Quant a la normativització de la llengua, a partir dels resultats de l’experiment, podrem dir que els catalans són cada cop més conscients de la normativa lingüística catalana vigent, sobretot pel que fa a la identificació dels casos d’interferència d’origen castellà. Observarem també que els diferents tipus de planificació i política lingüística en aquesta situació lingüística van estretament lligats, ja que tots formen part de la mateixa realitat sociolingüística.This article examines the awareness of normative Catalan and Castilian, using an innovative fieldwork experiment. Fifty participants were required to identify instances of non-normative language interference in Catalan and Castilian, and based on the results, conclusions were drawn as to their awareness of current linguistic norms. The participants belonged to two age brackets: the younger group was between 25 and 35 years old, while the older group was between 55 and 65 years old. The theoretical background of the article focuses on the debates surrounding language policy and planning, particularly concerning corpus planning and linguistic codification, given that the experiment is evaluating the role of foreign interference within normative varieties of Catalan. Based on the present experimental results, we will say that Catalans are increasingly aware of the content of normative Catalan, above all with regard to the identification of non-normative Castilianisms. We will also observe that different types of language policy and planning within a given linguistic community are intrinsically linked, as they all form part of the same sociolinguistic reality.","AI","University of Bristol"
"Finding light in dark archives: Using AI to connect context and content in email","https://research-information.bris.ac.uk/en/publications/finding-light-in-dark-archives-using-ai-to-connect-context-and-co","Decker, S.; Kirsch, D.; Kuppili Venkata, S.; Nix, A.","2022","Email archives are important historical resources, but access to such data poses a unique archival challenge and many born-digital collections remain dark, while questions of how they should be effectively made available are answered. This paper contributes to the growing interest in preserving access to email by addressing the needs of users, in readiness for when such collections become more widely available. We argue that for the content of email to be meaningfully accessed, the context of email must form part of this access. In exploring this idea, we focus on discovery within large, multi-custodian archives of organisational email, where emails’ network features are particularly apparent. We introduce our prototype search tool, which uses AI-based methods to support user-driven exploration of email. Specifically, we integrate two distinct AI models that generate systematically different types of results, one based upon simple, phrase-matching and the other upon more complex, BERT embeddings. Together, these provide a new pathway to contextual discovery that accounts for the diversity of future archival users, their interests and level of experience.Keywords:","AI","University of Bristol"
"Skilling the Gap: 21 Conversations on Designing Education for Those Left Behind as Robotics and AI Advance","https://research-information.bris.ac.uk/en/publications/skilling-the-gap-21-conversations-on-designing-education-for-thos","Gemmell, L.; Hauert, S.; Wenham, L. J.","18 Jan 2021","Robotics and artificial intelligence (RAI) is advancing rapidly. These advances risk exacerbating inequalities unless the benefits are shared across society. Education in RAI is often aimed at business leaders and students. While education designed for these groups is needed, it is not accessible by everyone, and there is potential for people to be left behind. To understand the barriers in designing an educational scheme for those often missed by other initiatives, a pilot study was conducted. Twenty‐one semi‐structured interviews were held with Thought‐Leaders, Industry, Adult Educators, and Members of the Public. A thematic analysis was used to allow themes not previously thought of to arise. Looking at the findings through the lens of leaving no one behind presents three themes, which need to be addressed for education to be successful. First, as well as education for those designing RAI and education for everyday life, there needs to be education for those working with RAI. Second, work is needed to overcome preconceptions. The views of learners on RAI, potential “gatekeeping” of experts, and attitudes to training from industry can create barriers to education. Finally, education should be co‐designed with communities to ensure it is relevant to the learners' needs and lives.","AI","University of Bristol"
"Reporting guideline for the early-stage clinical evaluation of decision support systems driven by artificial intelligence: DECIDE-AI","https://research-information.bris.ac.uk/en/publications/reporting-guideline-for-the-early-stage-clinical-evaluation-of-de"," & 4 others; Weber, W.; Wheatstone, P.; McCulloch, P.; DECIDE-AI expert group","18 May 2022","None","AI","University of Bristol"
"Toward Explainable AI Traders: Analysis of Algorithmic Traders Created via Deep Learning on Level-2 Limit Order Book Data","https://research-information.bris.ac.uk/en/publications/toward-explainable-ai-traders-analysis-of-algorithmic-traders-cre","Wray, A.; Coyne, O.; Meades, M.; Cliff, D.","22 Jul 2021","We show that a Deep Learning Neural Network (DLNN) learns to be a high-performing algorithmic trading system, operating purely from training-data inputs generated by passive observation of an existing successful trader T. That is, we point our DLNN system at trader T  and successfully have it learn from T 's trading activity, such that it then trades at least as well as T . Our system, DeepTrader, takes inputs derived from Level-2 market data, i.e. the market's Limit Order Book (LOB). Unusually, DeepTrader makes no explicit prediction of future prices. Instead, we train it purely on input-output pairs where in each pair the input is a snapshot S of Level-2 LOB data taken when T  issued a quote Q (i.e. a bid or an ask) to the market; and DeepTrader's desired output is to produce Q when it is shown S. That is, we train our DLNN by showing it the LOB data S  that T  saw at the time when T  issued quote Q; and in doing so our system comes to behave like T, acting as a profitable algorithmic trader. We evaluate DeepTrader against other algorithmic trading systems, including two that have repeatedly been shown to outperform human traders. DeepTrader matches or outperforms such pre-existing algorithmic trading systems. We analyze successful DeepTrader networks to identify what features are relied on and which features can be ignored. Our methods can in principle create an explainable copy of an arbitrary trader T  via imitative deep learning methods. ","AI","University of Bristol"
"AI-powered decision-making in facilitating insurance claim dispute resolution","https://research-information.bris.ac.uk/en/publications/ai-powered-decision-making-in-facilitating-insurance-claim-disput","Zhang, W.; Shi, J.; Wang, X.; Wynn, H.","23 Oct 2023","None","AI","University of Bristol"
"#COVIDisAirborne: AI-enabled multiscale computational microscopy of delta SARS-CoV-2 in a respiratory aerosol","https://research-information.bris.ac.uk/en/publications/covidisairborne-ai-enabled-multiscale-computational-microscopy-of","Oliveira, S.;  & 32 others; Welborn, M.; Christensen, A.; Smith, D. G.; Qiao, Z.; Sirumalla, S. K.; O'Connor, M.; Manby, F.; Anandkumar, A.; Hardy, D.; Phillips, J.; Stern, A.; Romero, J.; Clark, D.; Dorrell, M.; Maiden, T.; Huang, L.; McCalpin, J.; Woods, C.; Gray, A.; Williams, M.; Barker, B.; Rajapaksha, H.; Pitts, R.; Gibbs, T.; Stone, J.; Zuckerman, D. M.; Mulholland, A. J.; Miller, T.; Jha, S.; Ramanathan, A.; Chong, L.; Amaro, R. E.","Jan 2023","We seek to completely revise current models of airborne transmission of respiratory viruses by providing never-before-seen atomic-level views of the SARS-CoV-2 virus within a respiratory aerosol. Our work dramatically extends the capabilities of multiscale computational microscopy to address the significant gaps that exist in current experimental methods, which are limited in their ability to interrogate aerosols at the atomic/molecular level and thus obscure our understanding of airborne transmission. We demonstrate how our integrated data-driven platform provides a new way of exploring the composition, structure, and dynamics of aerosols and aerosolized viruses, while driving simulation method development along several important axes. We present a series of initial scientific discoveries for the SARS-CoV-2 Delta variant, noting that the full scientific impact of this work has yet to be realized.","AI","University of Bristol"
"‘If You’re Going to Trust the Machine, Then That Trust Has Got to Be Based on Something’: Validation and the Co-Constitution of Trust in Developing Artificial Intelligence (AI) for the Early Diagnosis of Pulmonary Hypertension (PH)","https://research-information.bris.ac.uk/en/publications/if-youre-going-to-trust-the-machine-then-that-trust-has-got-to-be","Winter, P.; Carusi, A.","22 Mar 2022","The role of Artificial Intelligence (AI) in clinical decision-making raises issues of trust. One issue concerns the conditions of trusting the AI which tends to be based on validation. However, little attention has been given to how validation is formed, how comparisons come to be accepted, and how AI algorithms are trusted in decision-making. Drawing on interviews with collaborative researchers developing three AI technologies for the early diagnosis of pulmonary hypertension (PH), we show how validation of the AI is jointly produced so that trust in the algorithm is built up through the negotiation of criteria and terms of comparison during interactions. These processes build up interpretability and interrogation, and co-constitute trust in the technology. As they do so, it becomes difficult to sustain a strict distinction between artificial and human/social intelligence.","AI","University of Bristol"
"Responsibly Buying Artificial Intelligence: A ‘Regulatory Hallucination’: A ‘Regulatory Hallucination’","https://research-information.bris.ac.uk/en/publications/responsibly-buying-artificial-intelligence-a-regulatory-hallucina","Sanchez-Graells, A.","6 Apr 2024","As part of its ‘pro-innovation’ approach to artificial intelligence (AI), the UK has left public sector AI procurement and deployment to ‘regulation by contract’ based on thin guidance. Borrowing from the description of AI ‘hallucinations’ as plausible but incorrect answers given with high confidence by AI systems, I argue that this is a ‘regulatory hallucination’: an incorrect answer to the challenge of regulating the procurement and use of AI by the public sector. The pretence that public buyers can ‘confidently and responsibly procure AI technologies’ can generate individual harms and broader negative social effects as the public sector ramps up AI adoption and accumulates a potentially significant stock of AI deployments across all areas of public sector activity. I sketch an alternative strategy to boost the effectiveness of the goals of AI regulation and the protection of individual rights and collective interests through the creation of an independent authority.","AI","University of Bristol"
"A Smart Home Testbed for Evaluating XAI with Non-Experts","https://research-information.bris.ac.uk/en/publications/a-smart-home-testbed-for-evaluating-xai-with-non-experts","McAreavey, K.; Bauters, K.; Liu, W.","3 Feb 2022","Smart homes are powered by increasingly advanced AI, yet are controlled by, and affect, non-experts. These non-expert home users are an under-represented stakeholder in the explainable AI (XAI) literature. In this paper we facilitate future XAI research by introducing a family of smart home applications serving as a testbed to evaluate XAI with non-experts. The testbed is a hybrid-AI system spanning several AI disciplines, including machine learning and AI planning. Applications include a smart home battery and smart thermostatic radiator valve (TRV). End-user functionality is representative of leading commercial products and relevant research applications. The testbed is based on a flexible software architecture and web-based user interface, supports a range of AI tools in a modular fashion, and can be easily deployed using inexpensive consumer hardware.","AI","University of Bristol"
"I, Robot, You, Consumer: Measuring Artificial Intelligence Types and their Effect on Consumers Emotions in Service","https://research-information.bris.ac.uk/en/publications/i-robot-you-consumer-measuring-artificial-intelligence-types-and-","Pantano, E.; Scarpi, D.","24 May 2022","This research draws upon the increasing usage of AI in service. It aims at understanding the extent to which AI systems have multiple intelligence types like humans and if these types arouse different emotions in consumers. To this end, the research uses a two-study approach: Study 1 builds and evaluates a scale for measuring different AI intelligence types. Study 2 evaluates consumers’ emotional responses to the different AI intelligences. The findings provide a measurement scale for evaluating different types of artificial intelligence against human ones, thus showing that artificial intelligences are configurable, describable, and measurable (Study 1), and influence positive and negative consumers’ emotions (Study 2). The findings also demonstrate that consumers display different emotions, in terms of happiness, excitement, enthusiasm, pride, inspiration, sadness, fear, anger, shame, and anxiety, and also emotional attachment, satisfaction, and usage intention when interacting with the different types of AI intelligences. Our scale builds upon human intelligence against AI intelligence characteristics while providing a guidance for future development of AI-based systems more similar to human intelligences.","AI","University of Bristol"
"Algorithmic bias: should students pay the price?","https://research-information.bris.ac.uk/en/publications/algorithmic-bias-should-students-pay-the-price","Smith, H.","12 Sept 2020","None","AI","University of Bristol"
"I, Robot, You, Consumer: Measuring Artificial Intelligence Types and their Effect on Consumers Emotions in Service","https://research-information.bris.ac.uk/en/publications/i-robot-you-consumer-measuring-artificial-intelligence-types-and-","Pantano, E.; Scarpi, D.","24 May 2022","This research draws upon the increasing usage of AI in service. It aims at understanding the extent to which AI systems have multiple intelligence types like humans and if these types arouse different emotions in consumers. To this end, the research uses a two-study approach: Study 1 builds and evaluates a scale for measuring different AI intelligence types. Study 2 evaluates consumers’ emotional responses to the different AI intelligences. The findings provide a measurement scale for evaluating different types of artificial intelligence against human ones, thus showing that artificial intelligences are configurable, describable, and measurable (Study 1), and influence positive and negative consumers’ emotions (Study 2). The findings also demonstrate that consumers display different emotions, in terms of happiness, excitement, enthusiasm, pride, inspiration, sadness, fear, anger, shame, and anxiety, and also emotional attachment, satisfaction, and usage intention when interacting with the different types of AI intelligences. Our scale builds upon human intelligence against AI intelligence characteristics while providing a guidance for future development of AI-based systems more similar to human intelligences.","AI","University of Bristol"
"An Existential Analysis of Consumers As “Incarnated Beings”: a Merleau-Pontyian Perspective","https://research-information.bris.ac.uk/en/publications/an-existential-analysis-of-consumers-as-incarnated-beings-a-merle","Lai, A-L.; Dermody, J.; Hammer-Lloyd, S.","2007","None","AI","University of Bristol"
"Exploring cadaveric organ donation: a 'mortal embodiment' perspective","https://research-information.bris.ac.uk/en/publications/exploring-cadaveric-organ-donation-a-mortal-embodiment-perspectiv","Lai, A-L.; Dermody, J.; Hammer-Lloyd, S.","Jun 2007","None","AI","University of Bristol"
"Interference and the ideal free distribution","https://research-information.bris.ac.uk/en/publications/interference-and-the-ideal-free-distribution","Moody, AI.; Houston, AI.","1995","None","AI","University of Bristol"
"The social turn of artificial intelligence","https://research-information.bris.ac.uk/en/publications/the-social-turn-of-artificial-intelligence","Cristianini, N.; Scantamburlo, T.; Ladyman, J. A. C.","4 Oct 2021","Social machines are systems formed by material and human elements interacting in a structured way. The use of digital platforms as mediators allows large numbers of humans to participate in such machines, which have interconnected AI and human components operating as a single system capable of highly sophisticated behavior. Under certain conditions, such systems can be understood as autonomous goal-driven agents. Many popular online platforms can be regarded as instances of this class of agent. We argue that autonomous social machines provide a new paradigm for the design of intelligent systems, marking a new phase in AI. After describing the characteristics of goal-driven social machines, we discuss the consequences of their adoption, for the practice of artificial intelligence as well as for its regulation.","AI","University of Bristol"
"The Art of Solo Dining: a Rhythmanalysis of Restaurant Spaces","https://research-information.bris.ac.uk/en/publications/the-art-of-solo-dining-a-rhythmanalysis-of-restaurant-spaces","Lai, A-L.; Lim, M.","2017","In this paper, we investigate how restaurants are inscribed by ‘heteronormative rhythms’ that privilege the dining experience of couples and families. Drawing on Henri Lefebvre’s theory of rhythmanalysis, we explore the dining experiences of solo diners and how they negotiate heteronormative spaces to mitigate marketplace exclusion and social arrhythmia.","AI","University of Bristol"
"Artificial intelligence, illegalised mobility and lucrative alchemy of border utopia","https://research-information.bris.ac.uk/en/publications/artificial-intelligence-illegalised-mobility-and-lucrative-alchem","Milivojevic, S.","21 Sept 2022","Artificial intelligence (AI) has captured the interest of academia and a range of industries. Much of this appeal is driven by the obsession with military and political supremacy, and a desire to control people and their movements. This article looks at the expansion and impact of AI systems deployed along physical borders on the mobility of illegalised non-citizens and border security in the Global North. Using the case study of Silicon Valley’s Anduril, the article focuses on the US–Mexico border and assesses AI’s role in hindering illegalised mobility and reconfiguring border control. Two key contributions are made in the paper. First, AI advances must become the focus of border criminologies, examined within the milieu from which the technology emerged. Second, virtual walls are commercial, political and anti-humanitarian. They are opaque, resembling alchemy, flawed but with profound consequences. The article adds to the debate on whether AI experiments should be permitted in border control.","AI","University of Bristol"
"Cyborg as Commodity: Exploring Conception of Self-Identity, Body and Citizenship within the Context of Emerging Transplant Technologies","https://research-information.bris.ac.uk/en/publications/cyborg-as-commodity-exploring-conception-of-self-identity-body-an-2","Lai, A. L.","2012","This paper explores how advances in transplant technologies shape conceptions of self-identity, embodiment and citizenship. Drawing on the posthuman writing of Donna Haraway and from phenomenological interviews, I explore ambivalence towards the commodification of the cyborg-body, suggesting that biotechnology may potentially lead to a dystopian posthuman consumer society.","AI","University of Bristol"
"""In the Flow: Materiality, Value and Rubbish in Lagos","https://research-information.bris.ac.uk/en/publications/in-the-flow-materiality-value-and-rubbish-in-lagos","Akponah, P. O.; Lai, A-L.; Higgins, M.","2020","Through an ethnographic study of waste handling in Lagos, we follow the ‘flow of rubbish’ to explore the value entanglement between urban dwellers and the materiality of rubbish. We draw on a practiced theory of value creation/destruction to understand how object recursively move in and out of its ‘rubbish’ state.","AI","University of Bristol"
"A Policy on the Use of Artificial Intelligence and Large Language Models in Peer Review","https://research-information.bris.ac.uk/en/publications/a-policy-on-the-use-of-artificial-intelligence-and-large-language","Munafò, M.","6 Dec 2023","Our readers will now be well aware of the astonishing growth in the capability and availability of artificial intelligence (AI) and Large Language Models (LLMs) through platforms such as ChatGPT. This presents both challenges and exciting opportunities for researchers. This includes the potential use of AI in evaluating submissions we receive to the journal.Time will tell where and how we can use AI to our advantage—in evaluating code that forms part of a submission for example. This is something we are actively exploring. However, currently, our policy is that—while we remain open to the potential opportunities offered by AI—we do not support the use of AI or LLMs as a substitute for human expertise in the review process.","AI","University of Bristol"
"Real-time implementation of lane detection and tracking","https://research-information.bris.ac.uk/en/publications/real-time-implementation-of-lane-detection-and-tracking","Wang, Y.; Dahnoun, N.; Ai, X.","18 Jun 2008","None","AI","University of Bristol"
"Nonlinear Dynamics of Interacting Populations","https://research-information.bris.ac.uk/en/publications/nonlinear-dynamics-of-interacting-populations","Khibnik, AI.; Krauskopf, B.","1998","None","AI","University of Bristol"
"Cyborg as Commodity: Exploring Conception of Self-Identity, Body and Citizenship within the Context of Emerging Transplant Technologies","https://research-information.bris.ac.uk/en/publications/cyborg-as-commodity-exploring-conception-of-self-identity-body-an","Lai, A-L.","2012","None","AI","University of Bristol"
"Evolutionarily stable levels of vigilance as a function of group size","https://research-information.bris.ac.uk/en/publications/evolutionarily-stable-levels-of-vigilance-as-a-function-of-group-","McNamara, JM.; Houston, AI.","1992","None","AI","University of Bristol"
"Crafting Cooperation: Regional International Institutions in Comparative Perspective","https://research-information.bris.ac.uk/en/publications/crafting-cooperation-regional-international-institutions-in-compa","Acharya, A.; Johnston, AI.","2007","None","AI","University of Bristol"
"Justice at the Forefront: Cultivating Felt Accountability towards ArtificialIntelligence among Healthcare Professionals","https://research-information.bris.ac.uk/en/publications/justice-at-the-forefront-cultivating-felt-accountability-towards-","Wang, W.; Wang, Y.; Chen, L.; Ma, R.; Zhang, M.","6 Mar 2024","The advent of AI has ushered in a new era of patient care, but with it emerges a contentious debate surrounding accountability for algorithmic medical decisions. Within this discourse, a spectrum of views prevails, ranging from placing accountability on AI solution providers to laying it squarely on the shoulders of healthcare professionals. In response to this debate, this study, grounded in the mutualistic partner choice (MPC) model of the evolution of morality, seeks to establish a configurational framework for cultivating felt accountability towards AI among healthcare professionals. This framework underscores two pivotal conditions: AI ethics enactment and trusting belief in AI and considers the influence of organizational complexity in the implementation of this framework. Drawing on Fuzzy-set Qualitative Comparative Analysis (fsQCA) of a sample of 401 healthcare professionals, this study reveals that a) focusing justice and autonomy in AI ethics enactment along with building trusting belief in AI reliability and functionality reinforces healthcare professionals’ sense of felt accountability towards AI, b) fostering felt accountability towards AI necessitates ensuring the establishment of trust in its functionality for high complexity hospitals, and c) prioritizing justice in AI ethics enactment and trust in AI reliability is essential for low complexity hospitals. ","AI","University of Bristol"
"Phenotypic plasticity as a state-dependent life-history decision","https://research-information.bris.ac.uk/en/publications/phenotypic-plasticity-as-a-state-dependent-life-history-decision","Houston, AI.; McNamara, JM.","1992","None","AI","University of Bristol"
"Optical-Tactile Sensor for Lump Detection Using Pneumatic Control","https://research-information.bris.ac.uk/en/publications/optical-tactile-sensor-for-lump-detection-using-pneumatic-control","Bewley, J.; Jenkinson, G. P.; Tzemanaki, A.","1 Jul 2021","None","AI","University of Bristol"
"Global study of a family of cubic Lienard equations","https://research-information.bris.ac.uk/en/publications/global-study-of-a-family-of-cubic-lienard-equations","Khibnik, AI.; Krauskopf, B.; Rousseau, C.","1998","None","AI","University of Bristol"
"Evolutionarily stable strategies in the repeated hawk-dove game","https://research-information.bris.ac.uk/en/publications/evolutionarily-stable-strategies-in-the-repeated-hawk-dove-game","Houston, AI.; McNamara, JM.","1991","None","AI","University of Bristol"
"A model of risk-sensitive foraging for a reproducing animal","https://research-information.bris.ac.uk/en/publications/a-model-of-risk-sensitive-foraging-for-a-reproducing-animal","McNamara, JM.; Merad, S.; Houston, AI.","1991","None","AI","University of Bristol"
"Real-time object tracking from video surveillance on dm642 dsp","https://research-information.bris.ac.uk/en/publications/real-time-object-tracking-from-video-surveillance-on-dm642-dsp","Ai, X.; Dahnoun, N.; Wang, Y.","18 Jun 2008","None","AI","University of Bristol"
"Charge- and spin-density-wave superconductors","https://research-information.bris.ac.uk/en/publications/charge-and-spin-density-wave-superconductors","Gabovich, AM.; Voitenko, AI.; Annett, JF.; Ausloos, M.","2001","None","AI","University of Bristol"
"Real time lowe cost pseudo-random noise continuous wave LIDAR","https://research-information.bris.ac.uk/en/publications/real-time-lowe-cost-pseudo-random-noise-continuous-wave-lidar","Ai, X.; Nock, RWR.; Dahnoun, N.; Rarity, JG.","23 Aug 2010","None","AI","University of Bristol"
"Risk-sensitive foraging: a review of the theory","https://research-information.bris.ac.uk/en/publications/risk-sensitive-foraging-a-review-of-the-theory","McNamara, JM.; Houston, AI.","1992","None","AI","University of Bristol"
"Cannibal or commodity fetish: Body as material interaction","https://research-information.bris.ac.uk/en/publications/cannibal-or-commodity-fetish-body-as-material-interaction","Lai, A. L.; Dermody, J.","2009","This paper seeks to address the call to bridge the dichotomous divide between subject and object within consumer research. Adopting an embodied perspective and drawing on our empirical research, we highlight the paradoxical meanings surrounding the fetishization of the body as a commoditized object as well as a kernel of personal history. We explore the extent to which participants are willing to overcome the depersonalizing transformation to their embodied self, as they negotiate the meanings surrounding the progressive objectification of the body, inherent in the practice of organ transplantation. Our analysis suggests the difficulty in delineating where the embodied subject ends (donor as self) and the commoditized object (donor as cadaver) begins. As such, the boundaries that mark the agentic capability of the embodied donor as commodity/intentional subject are mutable, indeterminate and intersubjectively emergent. We therefore seek to create a dialogue among consumer scholars to reconsider the body as the 'material interaction' between consuming subjects and material objects. Only in so doing, can we begin to advance the discipline beyond its essentialist roots.","AI","University of Bristol"
"Real-Time Disparity Map Estimation With Controlled Search Range","https://research-information.bris.ac.uk/en/publications/real-time-disparity-map-estimation-with-controlled-search-range","Fan, R.; Duanmu, S.; Ai, X.; Dahnoun, N.","13 Sept 2016","None","AI","University of Bristol"
"State-dependent life-history theory, and its implications for optimal clutch size","https://research-information.bris.ac.uk/en/publications/state-dependent-life-history-theory-and-its-implications-for-opti","McNamara, JM.; Houston, AI.","1992","None","AI","University of Bristol"
"Multifractal analysis for expanding interval maps with infinitely many branches","https://research-information.bris.ac.uk/en/publications/multifractal-analysis-for-expanding-interval-maps-with-infinitely","Fan, A-H.; Jordan, T. M.; Liao, L.; Rams, M.","Mar 2015","In this paper we investigate multifractal decompositions based on values of Birkhoff averages of functions from a class of symbolically continuous functions. This will be done for an expanding interval map with infinitely many branches and is a generalisation of previous work for expanding maps with finitely many branches. We show that there are substantial differences between this case and the setting where the expanding map has only finitely many branches.","AI","University of Bristol"
"N.S. Gumilev: Polnoe sobranie sochinenii v desiati tomakh.  Stihkotvoreniia, Poemy (1914-1918)","https://research-information.bris.ac.uk/en/publications/ns-gumilev-polnoe-sobranie-sochinenii-v-desiati-tomakh-stihkotvor","Basker, MG.; Vakhitova, TM.; Zobnin, IV.; Mikhailov, AI.; Prokof'ev, VA.; Filippov, GV.","1999","None","AI","University of Bristol"
"Optimality","https://research-information.bris.ac.uk/en/publications/optimality","Houston, AI.; McNamara, JM.","2002","None","AI","University of Bristol"
"Engineering design informatics","https://research-information.bris.ac.uk/en/publications/engineering-design-informatics","McMahon, C. A.; McAdams, D.; Liu, Y.","1 Nov 2016","None","AI","University of Bristol"
"Effect of continuous (intermittent) use on the power output of domestic microwave ovens","https://research-information.bris.ac.uk/en/publications/effect-of-continuous-intermittent-use-on-the-power-output-of-dome","Swain, MJ.; Ferron, S.; Pinto Coelho, AI.; Swain, MVL.","2006","None","AI","University of Bristol"
"Statistics of interior current distributions in two-dimensional open chaotic billiards","https://research-information.bris.ac.uk/en/publications/statistics-of-interior-current-distributions-in-two-dimensional-o","Saichev, AI.; Ishio, H.; Sadreev, AF.; Berggren, KF.","2002","None","AI","University of Bristol"
"Class talk: habitus and class in parental narratives of school choice","https://research-information.bris.ac.uk/en/publications/class-talk-habitus-and-class-in-parental-narratives-of-school-cho","Hill, B.; Lai, A. L.","1 Sept 2016","This article explores how social class is linguistically negotiated and contested in parental narratives of school choice in the British education marketplace. Our study reveals prevalent yet obscured vestiges of ‘class talk’, and in doing so, unmasks ‘micro-political’ acts of status claiming. Using interactional narrative interviewing with 30 parents, we explore how inter- and intra-class differences are emotionally expressed, thus exposing the embodied dispositions of parents’ habitus and its’ subtle influence on school choice. The parental narratives also unveil a moral and political tension between the neoliberal ideal of entrepreneurial self-advancement and an egalitarian sentiment for social equality. Our study therefore challenges the neoliberal educational policy of market choice in closing the attainment gap.","AI","University of Bristol"
"Demand curves, deprivation and welfare: A reply to Dawkins","https://research-information.bris.ac.uk/en/publications/demand-curves-deprivation-and-welfare-a-reply-to-dawkins","Houston, AI.","1997","None","AI","University of Bristol"
"Shedding the cocoon: A ""mortal embodiment"" perspective of organ donation in supporting and enhancing life","https://research-information.bris.ac.uk/en/publications/shedding-the-cocoon-a-mortal-embodiment-perspective-of-organ-dona","Lai, A. L.; Dermody, J.; Hanmer-Lloyd, S.","2007","This paper explores how potential female donors in the UK negotiate their ambivalent perceptions of cadaveric organ donation from a 'mortal embodiment' perspective. Specifically, we explore how the decision to dispossess body parts in the event of death challenges the notion of the body as the marker and annihilation of self under the contours of late modernity, Using a hermeneutic approach, multiple active interviews have been conducted with potential female donors, aged 21-30 who claim to harbour ambivalent perceptions towards organ donation. Through our 'rich and thick data' we reveal how potential donors actively rework socio-cultural constructs of the body by enacting various interpretive repertoires to make sense of their embodied self. We propose that the current organ donation promotional message of the ""gift-of-life"" should take into account the embodied self as an ongoing project of transitions and transformation that transcend biological death. Our paper therefore supports the research programs proposed by scholars of 'Consumer Culture Theory' and contributes to the recent call for 'Transformative Consumer Research'.","AI","University of Bristol"
"Block-matching disparity map estimation using controlled search range","https://research-information.bris.ac.uk/en/publications/block-matching-disparity-map-estimation-using-controlled-search-r","Ozgunalp, U.; Ai, X.; Zhang, Z.; Koc, G.; Dahnoun, N.","2015","None","AI","University of Bristol"
"On the need for a sensitive analysis of optimization models, or, ""This simulation is not as the former""","https://research-information.bris.ac.uk/en/publications/on-the-need-for-a-sensitive-analysis-of-optimization-models-or-th","Houston, AI.; McNamara, JM.; Thompson, WA.","1992","None","AI","University of Bristol"
"Amyloid-β1-42 oligomers enhance mGlu5R-dependent synaptic weakening via NMDAR activation and complement C5aR1 signaling","https://research-information.bris.ac.uk/en/publications/amyloid-%CE%B21-42-oligomers-enhance-mglu5r-dependent-synaptic-weakeni","Ng, A. N.; Salter, E. W.; Georgiou, J.; Bortolotto, Z. A.; Collingridge, G. L.","15 Dec 2023","Synaptic weakening and loss are well-correlated with the pathology of Alzheimer's disease (AD). Oligomeric amyloid beta (oAβ) is considered a major synaptotoxic trigger for AD. Recent studies have implicated hyperactivation of the complement cascade as the driving force for loss of synapses caused by oAβ. However, the initial synaptic cues that trigger pathological complement activity remain elusive. Here, we examined a form of synaptic long-term depression (LTD) mediated by metabotropic glutamate receptors (mGluRs) that is disrupted in rodent models of AD. Exogenous application of oAβ (1-42) to mouse hippocampal slices enhanced the magnitude of mGlu subtype 5 receptor (mGlu5R)-dependent LTD. We found that the enhanced synaptic weakening occurred via both N-methyl-D-aspartate receptors (NMDARs) and complement C5aR1 signaling. Our findings reveal a mechanistic interaction between mGlu5R, NMDARs, and the complement system in aberrant synaptic weakening induced by oAβ, which could represent an early trigger of synaptic loss and degeneration in AD.","AI","University of Bristol"
"Rapid regulation of endoplasmic reticulum dynamics in dendritic spines by NMDA receptor activation","https://research-information.bris.ac.uk/en/publications/rapid-regulation-of-endoplasmic-reticulum-dynamics-in-dendritic-s","Ng, A. N.; Doherty, A. J.; Lombroso, P. J.; Emptage, N. J.; Collingridge, G. L.","2014","Endoplasmic reticulum (ER) is motile within dendritic spines, but the mechanisms underlying its regulation are poorly understood. To address this issue, we have simultaneously imaged morphology and ER content of dendritic spines in cultured dissociated mouse hippocampal neurons. Over a 10 min period, spines were highly dynamic, with spines both increasing and decreasing in volume. ER was present in approximately 50% of spines and was also highly dynamic, with a net increase over this period of time. Inhibition of the endogenous activation of NMDA receptors resulted in a reduction in ER growth. Conversely, augmentation of the synaptic activation of NMDA receptors, by elimination of striatal-enriched protein tyrosine phosphatase (STEP), resulted in enhanced ER growth. Therefore, NMDA receptors rapidly regulate spine ER dynamics.","AI","University of Bristol"
"State-dependent life histories","https://research-information.bris.ac.uk/en/publications/state-dependent-life-histories","McNamara, JM.; Houston, AI.","1996","None","AI","University of Bristol"
"Ethical and Statistical Considerations in Models of Moral Judgments","https://research-information.bris.ac.uk/en/publications/ethical-and-statistical-considerations-in-models-of-moral-judgmen","Sivill, T.","16 Aug 2019","This work extends recent advancements in computational models of moral decision making by using mathematical and philosophical theory to suggest adaptations to state of the art. It demonstrates the importance of model assumptions and considers alternatives to the normal distribution when modeling ethical principles. We show how the ethical theories, utilitarianism and deontology can be embedded into informative prior distributions. We continue to expand the state of the art to consider ethical dilemmas beyond the Trolley Problem and show the adaptations needed to address this complexity. The adaptations made in this work are not solely intended to improve recent models but aim to raise awareness of the importance of interpreting results relative to assumptions made, either implicitly or explicitly, in model construction.","AI","University of Bristol"
"Experimental and numerical investigation of aerodynamic performance for airfoils with morphed trailing edges","https://research-information.bris.ac.uk/en/publications/experimental-and-numerical-investigation-of-aerodynamic-performan","Kamliya Jawahar, H.; Ai, Q.; Azarpeyvand, M.","Nov 2018","The aerodynamic performance of a NACA 0012 airfoil with morphing flaps were studied experimentally and numerically. Comprehensive aerodynamic measurements including pressure distribution, lift and drag forces and wake flow for airfoils with different morphing flap camber profiles were carried out over a wide range of angles of attack and chord-based Reynolds numbers. The results show that the morphing flap camber profiles significantly affect the aerodynamic performance and the downstream wake development. It was found that the highly cambered flap profiles provide higher lift coefficients compared to the moderately cambered flap profiles, with an insignificant reduction in the overall lift-to-drag ratio. Furthermore, the Q-criterion iso-surface results show that the separation near the trailing-edge is further delayed at high angles of attack for airfoils with high flap camber. This study shows that the effective design space of the morphing flaps can be expanded by taking into account the optimal aerodynamic performance requirements. The study also suggests that in order to achieve optimum aerodynamic performance, an independent surface morphing of the suction and pressure surface camber will be required to delay the onset of flow separation.","AI","University of Bristol"
"Energetic constraints and foraging efficiency","https://research-information.bris.ac.uk/en/publications/energetic-constraints-and-foraging-efficiency","Houston, AI.","1995","None","AI","University of Bristol"
"Wave function statistics for mesoscopic transport through chaotic open billiards: time reversibility, space reciprocity breaking and statistical crossover","https://research-information.bris.ac.uk/en/publications/wave-function-statistics-for-mesoscopic-transport-through-chaotic","Ishio, H.; Saichev, AI.; Sadreev, AF.; Berggren, KF.","2001","None","AI","University of Bristol"
"Non-monotonic dive to surface ratios: Comments on Walton et al. (1988)","https://research-information.bris.ac.uk/en/publications/non-monotonic-dive-to-surface-ratios-comments-on-walton-et-al-198","Houston, AI.","2000","None","AI","University of Bristol"
"Flying in the face of nature","https://research-information.bris.ac.uk/en/publications/flying-in-the-face-of-nature","Houston, AI.","2009","None","AI","University of Bristol"
"Ethical Principles for Reasoning about Value Preferences","https://research-information.bris.ac.uk/en/publications/ethical-principles-for-reasoning-about-value-preferences","Woodgate, J.","29 Aug 2023","To ensure alignment with human interests, AI must consider the preferences of stakeholders, which includes reasoning about values and norms. However, stakeholders may have different preferences, and dilemmas can arise concerning conflicting values or norms. My work applies normative ethical principles to resolve dilemma scenarios in satisfactory ways that promote fairness.","AI","University of Bristol"
"The effect of variability in the time to find hosts on the reproductive success of a parasitoid","https://research-information.bris.ac.uk/en/publications/the-effect-of-variability-in-the-time-to-find-hosts-on-the-reprod","Houston, AI.; McNamara, JM.; Godfray, HC.","1992","None","AI","University of Bristol"
