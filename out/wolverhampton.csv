"Title","Href","Author","Date","Abstract","Keywords","University Name"
"Trustworthy and efficient routing algorithm for IoT-FinTech applications using non-linear Lévy Brownian generalized normal distribution optimization","https://wlv.openrepository.com/handle/2436/624307","Sadiq, Ali Safaa; Dehkordi, Amin Abdollahi; Mirjalili, Seyedali; Too, Jingwei; Pillai, Prashant","September 2021","The huge advancement in the field of communication has pushed the innovation pace towards a new concept in the context of Internet of Things (IoT) named IoT for Financial Technology applications (IoT-FinTech). The main intention is to leverage the businesses’ income and reducing cost by facilitating the benefits enabled by IoT-FinTech technology. To do so, some of the challenging problems that mainly related to routing protocols in such highly dynamic, unreliable (due to mobility) and widely distributed network need to be carefully addressed. This paper therefore focuses on developing a new trustworthy and efficient routing mechanism to be used in routing data traffic over IoT-FinTech mobile networks. A new Non-linear Lévy Brownian Generalized Normal Distribution Optimization (NLBGNDO) algorithm is proposed to solve the problem of finding an optimal path from source to destination sensor nodes to be used in forwarding FinTech’s related data. We also propose an objective function to be used in maintaining trustworthiness of the selected relay-node candidates by introducing a trust-based friendship mechanism to be measured and applied during each selection process. The formulated model also considering node’s residual energy, experienced response time, and inter-node distance (to figure out density/sparsity ratio of sensor nodes). Results demonstrate that our proposed mechanism could maintain very wise and efficient decisions over the selection period in comparison with other methods.","Tech","University of Wolverhampton"
"The genetics and molecular biology of marine fungi","https://wlv.openrepository.com/handle/2436/29587","Hooley, Paul; Whitehead, Michael P.","January 2006","Interest in the genetics of marine fungi has focused upon the basis of stress adaptation and the control of the production of secondary metabolites and enzymes. Analysis by molecular genetics has been applied to marine fungal taxonomy, phylogeny and species identification. The advent of the Debaryomyces hansenii genome project and the influence of climate change on this research are discussed.","Marine","University of Wolverhampton"
"Swords and ploughshares: an analysis of the origins and implementation of the US Marine Corps' counterinsurgency strategy in Vietnam between March 1965 and November 1968","https://wlv.openrepository.com/handle/2436/140193","Strachan-Morris, David","January 2010","This thesis analyses the United States Marine Corps’ counterinsurgency strategy in Vietnam between March 1965 and November 1968, filling a major gap in the existing literature by forensically examining the primary source records maintained by the United States Marines to produce an assessment of the effectiveness of the strategy. It provides a useful corollary to the diplomatic and military histories of the war because not only does it examine operational-level thinking about the war but it analyses the intellectual antecedents of the Marines’ counterinsurgency strategy to answer the important questions about why the Marines chose to emphasis pacification and the ‘ink blot’ strategy rather than conducting a more conventional campaign that focused upon the destruction of enemy forces. The Marines’ own experience of counterinsurgency in the early part of the 20th Century, as well as the work of counterinsurgency theorists of the 1950s and 1960s, had a considerable impact upon their approach to the Vietnam War. The decision of the senior Marine commanders to adopt a pacification strategy along the lines of the ‘ink blot’ approach promulgated by these French and British counterinsurgency experts was partly the result of their view of the political nature of the war and partly the result of the reality they faced on the ground. At the time the Marines deployed to Vietnam their mission was to protect three bases on the coast in the northern provinces of South Vietnam and the Marines realised that the security of these establishments could be greatly improved if the population supported the Marines (and, by extension the South Vietnamese government) rather than the insurgents. Therefore, the ‘spreading ink blot’ of pacification was a product of the need to improve security as well as an attempt to challenge the political nature of communist revolutionary warfare. The metrics used to measure progress in the war were flawed, but there are other indicators within the Marines’ records that show they were conducting an effective and appropriate counterinsurgency campaign, within the limitations imposed by lack of resources and general inability to influence the war as a whole. When the Tet Offensive was launched in early 1968, the Marines use of pacification as ‘defence in depth’ allowed them to successfully defend the coastal enclaves by countering both the political and military efforts of the North Vietnamese in those areas.","Marine","University of Wolverhampton"
"Environmental cleaning mission Bioconversion of oxidatively fragmented polyethylene plastic waste to value-added copolyesters","https://wlv.openrepository.com/handle/2436/622982","Tchuenbou-Magaia, Fideline; ITOHOWO EKERE, ANABEL; Johnston, Brian; Zięba, Magdalena; Chaber, Paweł; Adamus, Grazyna; Barsi, David; AMARO, LUCÍA PÉREZ; Chiellini, Emo; Radecka, Izabela","December 2019","The innovative recycling method, we are proposing, relies upon the controlled oxidative fragmentation of waste LDPE plastic to the inexpensive substrates for future sustainable production of PHAs with the aid of  Cupriavidus necator. LDPE oxidized fragments (PE-F) were obtained from the re-engineering LDPE film by means of pro-oxidant/pro-degradant additives, followed by treatment under natural UV light. Cupriavidus necator was grown in either tryptone soya broth (TSB) or basal salt medium (BSM) supplemented with PE-F for 48 h.  PHA production was higher in TSB supplemented with PE-F (29%) than in TSB alone (only 0.6%). No PHA was detected in either BSM alone or BSM supplemented with PE-F. The recovered PHA was characterized using GPC, NMR, and electrospray ionization tandem mass spectrometry (ESI-MS/MS). These analytical tools applied confirmed that the resulting PHA was a terpolymer having an average molar mass of 624 kg/mol and consisting of 3-hydroxybutyrate (HB), 3-hydroxyvalerates (HV) and 3-hydroxyhexanoate (HH) co-monomer units randomly distributed along the chain backbone.","Marine","University of Wolverhampton"
"Nonlinear marine predator algorithm: A cost-effective optimizer for fair power allocation in NOMA-VLC-B5G networks","https://wlv.openrepository.com/handle/2436/624730","Sadiq, Ali Safaa; Dekhordi, Amin Abdollahi; Mirjalili, Seyedali; Pham, Quoc Viet","May 2022","This paper is an influential attempt to identify and alleviate some of the issues with the recently proposed optimization technique called the Marine Predator Algorithm (MPA). With a visual investigation of its exploratory and exploitative behavior, it is observed that the transition of search from being global to local can be further improved. As an extremely cost-effective method, a set of nonlinear functions is used to change the search patterns of the MPA algorithm. The proposed algorithm is called Nonlinear Marin Predator Algorithm (NMPA) is tested on a set of benchmark functions. A comprehensive comparative study shows the superiority of the proposed method compared to the original MPA and even other recent meta-heuristics. The paper also considers solving a real-world case study around power allocation in non-orthogonal multiple access (NOMA) and visible light communications (VLC) for Beyond 5G (B5G) networks to showcase the applicability of the NMPA algorithm. NMPA algorithm shows its superiority in solving a wide range of benchmark functions as well as obtaining fair power allocation for multiple users in NOMA-VLC-B5G systems compared with the state-of-the-art algorithms.","Marine","University of Wolverhampton"
"""Seagoing purposes indispensable to the defence of this country:"" Policy Pitfalls of Great Britain's Early Ironclads","https://wlv.openrepository.com/handle/2436/27166","Fuller, Howard","January 2003","None","Navy","University of Wolverhampton"
"""This Country Now Occupies the Vantage Ground"": Union Monitors vs. the British Navy","https://wlv.openrepository.com/handle/2436/27195","Fuller, Howard","January 2006","None","Navy","University of Wolverhampton"
"Iron lion or paper tiger? The myth of British naval intervention in the American Civil War","https://wlv.openrepository.com/handle/2436/622825","Fuller, Howard","January 2015","When it comes to the thought-provoking subject of foreign intervention in the Civil War, especially by Great Britain, much of the history has been more propaganda than proper research; fiction over fact. In 1961, Kenneth Bourne offered up a fascinating article on “British Preparations for War with the North, 1861–1862” for the English Historical Review. While focusing largely on the military defense of Canada during the Trent Affair, Bourne also stressed that Britain’s “position at sea was by no means so bad,” though he potentially confused the twentieth-century reader by referring to “battleships” rather than (steam-powered, sail, and screw-propelled) wooden ships-of-the-line, for example. This blurred the important technological changes that were certainly in play by 1861—and not necessarily in Britain’s favor. The Great Lakes the British considered to be largely a write-off as there were no facilities in place for building ironclads, much less floating wooden gunboats up frozen rivers and canals during the long winter season. American commerce and industrialization in the Midwest, on the other hand, had led to booming local ports like Chicago, Detroit, Toledo, and Cleveland—all facilitated by new railroads. Of course, Parliament had not seen to maximizing the defense of the British Empire’s many frontiers and outposts over the years. If anything, the legendary reputation of the Royal Navy continually undermined that imperative. That left the onus of any real war against the United States to Britain’s ability to lay down a naval offensive. And while Bourne was content to trust the judgment of an anonymous British officer in Colburn’s United Service Magazine that “1273 guns” were available to Vice Admiral Sir Alexander Milne’s North American and West Indies naval forces during the Trent crisis, the same publication also went on to warn its contemporary British readers that “in calculating the power of the Northern States at sea, we must not be deluded by the ships actually in existence, but must reckon on those that may be built.”  The author might have added that of the 86 guns of Milne’s flagship, HMS Nile, for example, or the 91 guns of the newer Agamemnon (launched in 1852 and reinforcing the British naval base at Bermuda from Gibraltar), no more than a third were 8-inch (65 cwt. ) shell-firing guns, the rest being 32-pounders in use since the Napoleonic era.  In fact, the more deep-draft, screw-propelled ships-of-the-line the Admiralty dispatched to Milne, the more nervous he became. The 101-gun Conqueror ran aground in the Bahamas on December 13, 1861, a total loss. The British admiral pleaded for more shallow-draft paddle steamers, like those in use by the Union navy. Indeed, it was the lighter craft of the Yankees which proved better adapted for warfare in American waters.","Navy","University of Wolverhampton"
"Much in Little: John Ericsson and His Monitor, Review-Essay of 'Our Little Monitor: The Greatest Invention of the Civil War', by Anna Gibson Holloway and Jonathan W. White","https://wlv.openrepository.com/handle/2436/622794","Fuller, Howard","July 2019","None","Navy","University of Wolverhampton"
"The Whole Character of Maritime Life: British Reactions to the USS Monitor and the American Ironclad Experience","https://wlv.openrepository.com/handle/2436/27167","Fuller, Howard","January 2002","None","Navy","University of Wolverhampton"
"Adrian G. Marshall, Nemesis: The First Iron Warship and Her World","https://wlv.openrepository.com/handle/2436/623432","Fuller, Howard","November 2017","None","Navy","University of Wolverhampton"
"Clad in Iron: The American Civil War and the Challenge of British Naval Power","https://wlv.openrepository.com/handle/2436/27168","Fuller, Howard","January 2007","This work addresses many persistent misconceptions of what the monitors were for, and why they failed in other roles associated with naval operations of the Civil War (such as the repulse at Charleston, April 7, 1863). Monitors were 'ironclads'- not fort-killers. Their ultimate success is to be measured not in terms of spearheading attacks on fortified Southern ports but in the quieter, much more profound, strategic deterrence of Lord Palmerston's ministry in London, and the British Royal Navy's potential intervention. During the American Civil War, one of the greatest fears of the Union government was that the United Kingdom might intervene on the side of the Confederacy. This book is a unique study that combines a lively and colourful narrative with a fresh interpretation of the American effort to avoid a naval war with Great Britain. The author chronicles the growth and development of the Union ""Ironclads,"" beginning with U.S.S. Monitor, during the American Civil War.Unlike other similar histories, however, the author does not simply recount the battle actions of these metal monsters. Instead, he crafts a fast-paced narrative that focuses on the military men and government officials who drove the decision-making processes, and outlines the international ramifications of the revolution in naval affairs that took place in the 1860s. He demonstrates that Federal ironclads were not constructed solely in response to their Confederate counterparts, but, even more importantly, to counter the ocean-going iron ships of the Royal Navy. The author places the naval developments of the Civil War within the broader context of Anglo-American relations and the rapidly developing international rivalry between the United States and Britain. The wide reaching implications of the technological advances, and the unprecedented expansion of the U.S. Navy are usually depicted as a sidebar to the main events of the Civil War. This work, however, brings a new perspective to this important yet overlooked aspect of diplomacy during this time.","Navy","University of Wolverhampton"
"The Falklands Conflict as a Media War","https://wlv.openrepository.com/handle/2436/26323","Badsey, Stephen","January 2004","A fascinating new insight into the Falklands Conflict, covering every aspect of its origins and the political and diplomatic response to the Argentinean action as well as illuminating accounts of the military action to retake the islands, at every level of command. In June 2002, exactly twenty years after the cessation of hostilities between Britain and Argentina, many of the key participants came together at a major international conference. This conference, held at the Royal Military Academy, Sandhurst and organized jointly by RMA Sandhurst and her sister institution Britannia Royal Naval College, Dartmouth, aimed to re-examine the events of spring 1982 from the perspective that only twenty intervening years can bring. The Conference mixed those who had participated in the events of spring and early summer 1982, diplomats, politicians, civil servants, soldiers, sailors and airmen, with historians, political scientists and journalists. These accounts and interpretations of the conflict shed new light on one of the most interesting and controversial episodes in recent British history.","Navy","University of Wolverhampton"
"‘Had we used the Navy’s bare fist instead of its gloved hand’: The absence of coastal assault vessels in the Royal Navy by 1914","https://wlv.openrepository.com/handle/2436/622793","Fuller, Howard","June 2017","This paper will briefly chart how and why the Royal Navy chose not to develop coastal assault vessels—namely heavy-gunned, light-draught monitors specially designed to absorb damage from modern mines or torpedoes—until well after the First World War began. Churchill and Fisher envisaged these particular men-of-war as the floating equivalent of tanks, both ‘intended to restore to the stronger power an effective means of the offensive’. Only when they were finally launched and deployed in sufficient numbers could serious plans for projecting power directly against the German coastline be safely considered. So where were the monitors before the war?","Navy","University of Wolverhampton"
"Using value iteration to solve sequential decision problems in games","https://wlv.openrepository.com/handle/2436/31519","Hartley, Thomas; Mehdi, Qasim; Gough, Norman","January 2004","Solving sequential decision problems in computer games, such as non-player character (NPC) navigation, can be quite a complex task. Current games tend to rely on scripts and finite state machines (FSM) to control AI opponents. These approaches however have shortcomings; as a result academic AI techniques may be a more desirable solution to solve these types of problems. This paper describes the process of applying the value iteration algorithm to an AI engine, which can be applied to a computer game. We also introduce a new stopping criterion called game value iteration, which has been designed for use in 2D real time computer games and we discuss results from experiments conducted on the AI engine. We also outline our conclusions which state that the value iteration and the newly introduced game value iteration algorithms can be successfully applied to intelligent NPC behaviour in computer games; however there are certain problems, such as execution speed, which need to be addressed when dealing with real time games.","AI","University of Wolverhampton"
"Applying Markov decision processes to 2D real time games","https://wlv.openrepository.com/handle/2436/31518","Hartley, Thomas; Mehdi, Qasim; Gough, Norman","January 2004","This paper presents the outcomes of a research project into the field of artificial intelligence (AI) and computer game AI. The project considered the problem of applying AI techniques to computer games. Current commercial computer games tend to use complex scripts to control AI opponents. This can result in poor and predictable gameplay. The use of academic AI techniques is a possible solution to overcome these shortcomings. This paper describes the process of applying Markov decision processes (MDPs) using the value iteration algorithm to a 2D real time computer game. We also introduce a new stopping criterion for value iteration, which has been designed for use in computer games and we discuss results from experiments conducted on the MDPs AI engine. This paper also outlines conclusions about how successful MDPs are in relation to a real computer game AI engine and how useful they might be to computer games developers.","AI","University of Wolverhampton"
"Encoding sound by polynomial interpolation for intelligent dynamic music in computer games","https://wlv.openrepository.com/handle/2436/31533","Burley, M.A.; Gough, Norman; Mehdi, Qasim; Natkin, Stephane","January 2004","Current research in computer music composition almost exclusively involves the manipulation of music stored as MIDI data. While this allows direct access to the structure of music, it creates limitations in realism for the end result of such techniques. This paper describes a method designed to represent music in a form that facilitates the use of existing processing techniques while conserving the ‘real-world’ attributes of music recorded in PCM format giving computergame developers a facility for the production of variations on a pre-recorded theme, whatever the original source. Experimental results are presented to demonstrate that polynomial interpolation is a viable technique.","AI","University of Wolverhampton"
"TransQuest: Translation quality estimation with cross-lingual transformers","https://wlv.openrepository.com/handle/2436/624693","Ranasinghe, Tharindu; Orasan, Constantin ; Mitkov, Ruslan","December 2020","Recent years have seen big advances in the field of sentence-level quality estimation (QE), largely as a result of using neural-based architectures. However, the majority of these methods work only on the language pair they are trained on and need retraining for new language pairs. This process can prove difficult from a technical point of view and is usually computationally expensive. In this paper we propose a simple QE framework based on cross-lingual transformers, and we use it to implement and evaluate two different neural architectures. Our evaluation shows that the proposed methods achieve state-of-the-art results outperforming current open-source quality estimation frameworks when trained on datasets from WMT. In addition, the framework proves very useful in transfer learning settings, especially when dealing with low-resourced languages, allowing us to obtain very competitive results.","AI","University of Wolverhampton"
"RGCL at SemEval-2020 task 6: Neural approaches to definition extraction","https://wlv.openrepository.com/handle/2436/624692","Ranasinghe, Tharindu; Plum, Alistair; Orasan, Constantin ; Mitkov, Ruslan","December 2020","This paper presents the RGCL team submission to SemEval 2020 Task 6: DeftEval, subtasks 1 and 2. The system classifies definitions at the sentence and token levels. It utilises state-of-the-art neural network architectures, which have some task-specific adaptations, including an automatically extended training set. Overall, the approach achieves acceptable evaluation scores, while maintaining flexibility in architecture selection.","AI","University of Wolverhampton"
"A survey on deep transfer learning and edge computing for mitigating the COVID-19 pandemic","https://wlv.openrepository.com/handle/2436/623336","Sufian, Abu; Ghosh, Anirudha; Al-Shakarchi, Ali; Smarandache, Florentin","June 2020","Global Health sometimes faces pandemics as are currently facing COVID-19 disease. The spreading and infection factors of this disease are very high. A huge number of people from most of the countries are infected within six months from its first report of appearance and it keeps spreading. The required systems are not ready up to some stages for any pandemic; therefore, mitigation with existing capacity becomes necessary. On the other hand, modern-era largely depends on Artificial Intelligence(AI) including Data Science; and Deep Learning(DL) is one of the current flag-bearer of these techniques. It could use to mitigate COVID-19 like pandemics in terms of stop spread, diagnosis of the disease, drug & vaccine discovery, treatment, patient care, and many more. But this DL requires large datasets as well as powerful computing resources. A shortage of reliable datasets of a running pandemic is a common phenomenon. So, Deep Transfer Learning(DTL) would be effective as it learns from one task and could work on another task. In addition, Edge Devices(ED) such as IoT, Webcam, Drone, Intelligent Medical Equipment, Robot, etc. are very useful in a pandemic situation. These types of equipment make the infrastructures sophisticated and automated which helps to cope with an outbreak. But these are equipped with low computing resources, so, applying DL is also a bit challenging; therefore, DTL also would be effective there. This article scholarly studies the potentiality and challenges of these issues. It has described relevant technical backgrounds and reviews of the related recent state-of-the-art. This article also draws a pipeline of DTL over Edge Computing as a future scope to assist the mitigation of any pandemic.","AI","University of Wolverhampton"
"Farmers perceptions of climate change related events in Shendam and Riyom, Nigeria","https://wlv.openrepository.com/handle/2436/622847","Goyol, S; Pathirage, C","December 2018","© 2018 by the authors. Although agriculture in Nigeria is the major source of income for about 70% of the active population, the impact of agrarian infrastructure on boosting productivity and supporting livelihoods has increased. Climate change and the increasing trend of climate-related events in Nigeria challenge both the stability of agrarian infrastructure and livelihood systems. Based on case studies of two local communities in Plateau state in Nigeria, this paper utilizes a range of perceptions to examine the impacts of climate-related events on agrarian infrastructures and how agrarian livelihood systems are, in turn, affected. Data are obtained from a questionnaire survey (n = 175 farmers) and semi-structured interviews (n = 14 key informants). The study identifies local indicators of climate change, high risks climate events and the components of agrarian infrastructures that are at risk from climate events. Findings reveal that, changes in rainfall and temperature patterns increase the probability of floods and droughts. They also reveal that, although locational differences account for the high impact of floods on road transport systems and droughts on irrigation infrastructures, both have a chain of negative effects on agricultural activities, economic activities and livelihood systems. A binomial logistic regression model is used to predict the perceived impact levels of floods and droughts, while an in-depth analysis is utilized to corroborate the quantitative results. The paper further stresses the need to strengthen the institutional capacity for risk reduction through the provision of resilient infrastructures, as the poor conditions of agrarian infrastructure were identified as dominant factors on the high impact levels.","AI","University of Wolverhampton"
"E-AI an emotion architecture for agents in games & virtual worlds","https://wlv.openrepository.com/handle/2436/105038","Slater, Stuart","January 2010","Characters in games and virtual worlds continue to gain improvements in both their visual appearance and more human-like behaviours with each successive generation of hardware. One area that seemingly would need to be addressed if this evolution in human-like characters is to continue is in the area of characters with emotions. To begin addressing this, the thesis focuses on answering the question “Can an emotional architecture be developed for characters in games and virtual worlds, that is built upon a foundation of formal psychology? Therefore a primary goal of the research was to both review and consolidate a range of background material based on the psychology of emotions to provide a cohesive foundation on which to base any subsequent work. Once this review was completed, a range of supplemental material was investigated including computational models of emotions, current implementations of emotions in games and virtual worlds, machine learning techniques suitable for implementing aspects of emotions in characters in virtual world, believability and the role of emotions, and finally a discussion of interactive characters in the form of chat bots and non-player characters. With these reviews completed, a synthesis of the research resulted in the defining of an emotion architecture for use with pre-existing agent behaviour systems, and a range of evaluation techniques applicable to agents with emotions. To support validation of the proposed architecture three case studies were conducted that involved applying the architecture to three very different software platforms featuring agents. The first was applying the architecture to combat bots in Quake 3, the second to a chat bot in the virtual world Second Life, and the third was to a web chat bot used for e-commerce, specifically dealing with question and answers about the companies services. The three case studies were supported with several small pilot evaluations that were intended to look at different aspects of the implemented architecture including; (1) Whether or not users noticed the emotional enhancements. Which in the two small pilot studies conducted, highlighted that the addition of emotions to characters seemed to affect the user experience when the encounter was more interactive such as in the Second Life implementation. Where the interaction occurred in a combat situation with enemies with short life spans, the user experience seemed to be greatly reduced. (2) An evaluation was conducted on how the combat effectiveness of combat bots was affected by the addition of emotions, and in this pilot study it was found that the combat effectiveness was not quite statistically reduced, even when the bots were running away when afraid, or attacking when angry even if close to death. In summary, an architecture grounded in formal psychology is presented that is suitable for interactive characters in games and virtual worlds, but not perhaps ideal for applications where user interaction is brief such as in fast paced combat situations. This architecture has been partially validated through three case studies and includes suggestions for further work especially in the mapping of secondary emotions, the emotional significance of conversations, and the need to conduct further evaluations based on the pilot studies.","AI","University of Wolverhampton"
"Generative BIM workspace for AEC conceptual design automation: prototype development","https://wlv.openrepository.com/handle/2436/623510","Abrishami, S; Goulding, J; Rahimian, F","July 2020","Purpose: The integration and automation of the whole design and implementation process have become a pivotal factor in construction projects. Problems of process integration, particularly at the conceptual design stage, often manifest through a number of significant areas, from design representation, cognition and translation to process fragmentation and loss of design integrity. Whilst building information modelling (BIM) applications can be used to support design automation, particularly through the modelling, amendment and management stages, they do not explicitly provide whole design integration. This is a significant challenge. However, advances in generative design now offer significant potential for enhancing the design experience to mitigate this challenge. Design/methodology/approach: The approach outlined in this paper specifically addresses BIM deficiencies at the conceptual design stage, where the core drivers and indicators of BIM and generative design are identified and mapped into a generative BIM (G-BIM) framework and subsequently embedded into a G-BIM prototype. This actively engages generative design methods into a single dynamic BIM environment to support the early conceptual design process. The developed prototype followed the CIFE “horseshoe” methodology of aligning theoretical research with scientific methods to procure architecture, construction and engineering (AEC)-based solutions. This G-BIM prototype was also tested and validated through a focus group workshop engaging five AEC domain experts. Findings: The G-BIM prototype presents a valuable set of rubrics to support the conceptual design stage using generative design. It benefits from the advanced features of BIM tools in relation to illustration and collaboration (coupled with BIM's parametric change management features). Research limitations/implications: This prototype has been evaluated through multiple projects and scenarios. However, additional test data is needed to further improve system veracity using conventional and non-standard real-life design settings (and contexts). This will be reported in later works. Originality/value: Originality and value rest with addressing the shortcomings of previous research on automation during the design process. It also addresses novel computational issues relating to the implementation of generative design systems, where, for example, instead of engaging static and formal description of the domain concepts, G-BIM actively enhances the applicability of BIM during the early design stages to generate optimised (and more purposeful) design solutions.","AI","University of Wolverhampton"
"An exploratory analysis of multilingual word-level quality estimation with cross-lingual transformers","https://wlv.openrepository.com/handle/2436/624378","Ranasinghe, Tharindu; Orasan, Constantin ; Mitkov, Ruslan","August 2021","Most studies on word-level Quality Estimation (QE) of machine translation focus on language-specific models. The obvious disadvantages of these approaches are the need for labelled data for each language pair and the high cost required to maintain several language-specific models. To overcome these problems, we explore different approaches to multilingual, word-level QE. We show that these QE models perform on par with the current language-specific models. In the cases of zero-shot and few-shot QE, we demonstrate that it is possible to accurately predict word-level quality for any given new language pair from models trained on other language pairs. Our findings suggest that the word-level QE models based on powerful pre-trained transformers that we propose in this paper generalise well across languages, making them more useful in real-world scenarios.","AI","University of Wolverhampton"
"Towards an interpretable model for automatic classification of endoscopy images","https://wlv.openrepository.com/handle/2436/624897","García-Aguirre, Rogelio; Torres Treviño, Luis; Navarro-López, Eva María ; González-González, José Alberto","October 2022","Deep learning strategies have become the mainstream for computer-assisted diagnosis tools development since they outperform other machine learning techniques. However, these systems can not reach their full potential since the lack of understanding of their operation and questionable generalizability provokes mistrust from the users, limiting their application. In this paper, we generate a Convolutional Neural Network (CNN) using a genetic algorithm for hyperparameter optimization. Our CNN has state-of-the-art classification performance, delivering higher evaluation metrics than other recent papers that use AI models to classify images from the same dataset. We provide visual explanations of the classifications made by our model implementing Grad-CAM and analyze the behavior of our model on misclassifications using this technique.","AI","University of Wolverhampton"
"Trustworthy and efficient routing algorithm for IoT-FinTech applications using non-linear Lévy Brownian generalized normal distribution optimization","https://wlv.openrepository.com/handle/2436/624307","Sadiq, Ali Safaa; Dehkordi, Amin Abdollahi; Mirjalili, Seyedali; Too, Jingwei; Pillai, Prashant","September 2021","The huge advancement in the field of communication has pushed the innovation pace towards a new concept in the context of Internet of Things (IoT) named IoT for Financial Technology applications (IoT-FinTech). The main intention is to leverage the businesses’ income and reducing cost by facilitating the benefits enabled by IoT-FinTech technology. To do so, some of the challenging problems that mainly related to routing protocols in such highly dynamic, unreliable (due to mobility) and widely distributed network need to be carefully addressed. This paper therefore focuses on developing a new trustworthy and efficient routing mechanism to be used in routing data traffic over IoT-FinTech mobile networks. A new Non-linear Lévy Brownian Generalized Normal Distribution Optimization (NLBGNDO) algorithm is proposed to solve the problem of finding an optimal path from source to destination sensor nodes to be used in forwarding FinTech’s related data. We also propose an objective function to be used in maintaining trustworthiness of the selected relay-node candidates by introducing a trust-based friendship mechanism to be measured and applied during each selection process. The formulated model also considering node’s residual energy, experienced response time, and inter-node distance (to figure out density/sparsity ratio of sensor nodes). Results demonstrate that our proposed mechanism could maintain very wise and efficient decisions over the selection period in comparison with other methods.","AI","University of Wolverhampton"
"Artificial intelligence to support publishing and peer review: A summary and review","https://wlv.openrepository.com/handle/2436/625277","Kousha, Kayvan ; Thelwall, Mike ","August 2023","Technology is being developed to support the peer review processes of journals, conferences, funders, universities, and national research evaluations. This literature and software summary discusses the partial or complete automation of several publishing-related tasks: suggesting appropriate journals for an article, providing quality control for submitted papers, finding suitable reviewers for submitted papers or grant proposals, reviewing, and review evaluation. It also discusses attempts to estimate article quality from peer review text and scores as well as from post-publication scores but not from bibliometric data. The literature and existing examples of working technology show that automation is useful for helping to find reviewers and there is good evidence that it can sometimes help with initial quality control of submitted manuscripts. Much other software supporting publishing and editorial work exists and is being used, but without published academic evaluations of its efficacy. The value of artificial intelligence (AI) to support reviewing has not been clearly demonstrated yet, however. Finally, whilst peer review text and scores can theoretically have value for post-publication research assessment, it is not yet widely enough available to be a practical evidence source for systematic automation.","AI","University of Wolverhampton"
"Artificial intelligence and the UK construction industry – empirical study","https://wlv.openrepository.com/handle/2436/624991","Jallow, Haddy; Renukappa, Suresh ; Suresh, Subashini ; Rahimian, Farzad","December 2022","There is a lack of research on the use of Artificial Intelligence (AI) within the construction sector in the UK.   Therefore, this research seeks to explore AI uses and its benefits on the UK construction industry. Given the new and unexplored nature of the research problem, a qualitative case study research methodology was adopted. Construction projects, which have adopted some of the AI forms all around the UK, are investigated extracting the use of the technology and how processes within the construction industry can benefit from the adoption of AI. Developing an AI system can benefit the construction industry in terms of the planning process, organisations have implemented AI systems to accomplish tasks such as tunnel inspections, safety hazard identifying and risk management. These implementations have proved to be successful and efficient improving production within the organisations.  This paper highlights the key uses and benefits of AI based systems within the construction industry. The business model was developed based on current work practices with AI and without AI. It is concluded that the industry as a whole should enhance coordination and cooperation across the value chain and agree on common goals and standards for the adoption of AI.","AI","University of Wolverhampton"
